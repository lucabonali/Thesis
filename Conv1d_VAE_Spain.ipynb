{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 500, 7)\n(34, 500, 7)\n(31, 500, 7)\n(35, 500, 7)\n(37, 500, 7)\n(34, 500, 7)\n(30, 500, 7)\n(35, 500, 7)\n(35, 500, 7)\n(35, 500, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "n_features = 7\n",
    "run_list = []\n",
    "\n",
    "def read_csvs():\n",
    "    scaler = StandardScaler()\n",
    "    for i in range(8):\n",
    "        title = \"Data/Spain_csv/\"+ str(i+1) + \"^_RUN.csv\"\n",
    "        data = pd.read_csv(title)\n",
    "        data = data.drop(columns=['Unnamed: 0'])\n",
    "        v = int(len(data)/100) * 100\n",
    "        data = data[:v]\n",
    "        data = scaler.fit_transform(data)\n",
    "        run_list.append(data)\n",
    "       \n",
    "        \n",
    "read_csvs()\n",
    "\n",
    "def prepare_sequences(data, batch_size, interval):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0] - batch_size, interval):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "\n",
    "    sequences = np.array(samples)\n",
    "\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "    print(trainX.shape)\n",
    "    return trainX\n",
    "\n",
    "\n",
    "for i, elem in enumerate(run_list):\n",
    "    run_list[i] = prepare_sequences(elem, 500, 500)\n",
    "    \n",
    "    \n",
    "data_list = np.array(run_list)\n",
    "\n",
    "val_data = data_list[-1]\n",
    "\n",
    "data_list = np.ravel(data_list[:7])\n",
    "print(data_list[0].shape)\n",
    "print(val_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['seconds','x','y','z','speed','acceleration','degrees']\n",
    "\n",
    "\n",
    "for i in run_list[1]:\n",
    "    df = pd.DataFrame(i, columns=columns)\n",
    "    plt.plot(df[\"x\"], df['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 500, 7)       0                                            \n__________________________________________________________________________________________________\nlstm_15 (LSTM)                  (None, 500, 100)     43200       encoder_input[0][0]              \n__________________________________________________________________________________________________\nlstm_16 (LSTM)                  (None, 10)           4440        lstm_15[0][0]                    \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 10)           110         lstm_16[0][0]                    \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 10)           110         lstm_16[0][0]                    \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 10)           0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 47,860\nTrainable params: 47,860\nNon-trainable params: 0\n__________________________________________________________________________________________________\n(None, 500, 10)\n(None, 500, 7)\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 10)                0         \n_________________________________________________________________\nDense_after_sampling (Dense) (None, 5000)              55000     \n_________________________________________________________________\nreshape_6 (Reshape)          (None, 500, 10)           0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 500, 7)            77        \n=================================================================\nTotal params: 55,077\nTrainable params: 55,077\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import objectives\n",
    "from keras.layers import RepeatVector, MaxPooling1D, LSTM, UpSampling1D\n",
    "\n",
    "input_shape = (500, n_features,)\n",
    "kernel_size = 7\n",
    "filters = 200\n",
    "latent_dim = 10\n",
    "beta = 1\n",
    "use_mse = True\n",
    "load_weights = False\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "\n",
    "for i in range(1):\n",
    "    x = LSTM(100, return_sequences=True)(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = LSTM(latent_dim, return_sequences=False)(x)\n",
    "# for i in range(2):\n",
    "#     x = Conv1D(filters=filters,\n",
    "#                kernel_size=7,\n",
    "#                padding='same')(x)\n",
    "#     x = MaxPooling1D(2)(x)\n",
    "#     filters = int(filters / 2)\n",
    "\n",
    "# \n",
    "# x = Flatten()(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "filters = filters * 2\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(500 * latent_dim, name='Dense_after_sampling')(latent_inputs)\n",
    "x = Reshape((500, latent_dim))(x)\n",
    "\n",
    "# for i in range(2):\n",
    "#     x = Conv1D(filters=filters,kernel_size=7, padding='same')(x)\n",
    "#     x = UpSampling1D(size=2)(x)\n",
    "#     filters = filters * 2\n",
    "    \n",
    "print(K.int_shape(x))   \n",
    "# x = RepeatVector(100)(x)    \n",
    "# outputs = LSTM(100)(x)\n",
    "outputs = Dense(7)(x)\n",
    "print(K.int_shape(outputs))\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "from keras.losses import mse\n",
    "\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n",
    "loss = reconstruction_loss + beta*kl_loss\n",
    "vae.add_loss(loss)\n",
    "\n",
    "vae.compile(optimizer='rmsprop', metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r35/35 [==============================] - 3s 96ms/step - loss: 1.0002 - val_loss: 1.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss improved from inf to 1.00264, saving model to Models/Weights/LSTM_weigths_spain.hdf5\nTrain on 34 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r34/34 [==============================] - 4s 111ms/step - loss: 0.9918 - val_loss: 1.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss improved from 1.00264 to 1.00133, saving model to Models/Weights/LSTM_weigths_spain.hdf5\nTrain on 31 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r31/31 [==============================] - 9s 285ms/step - loss: 0.9929 - val_loss: 1.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss improved from 1.00133 to 1.00099, saving model to Models/Weights/LSTM_weigths_spain.hdf5\nTrain on 35 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r35/35 [==============================] - 6s 171ms/step - loss: 1.0009 - val_loss: 1.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss improved from 1.00099 to 1.00006, saving model to Models/Weights/LSTM_weigths_spain.hdf5\nTrain on 37 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r37/37 [==============================] - 6s 155ms/step - loss: 0.9923 - val_loss: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss improved from 1.00006 to 0.99905, saving model to Models/Weights/LSTM_weigths_spain.hdf5\nTrain on 34 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r34/34 [==============================] - 6s 176ms/step - loss: 0.9896 - val_loss: 1.0009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss did not improve from 0.99905\nTrain on 30 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 5s 165ms/step - loss: 1.0007 - val_loss: 0.9988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss improved from 0.99905 to 0.99881, saving model to Models/Weights/LSTM_weigths_spain.hdf5\nTrain on 35 samples, validate on 35 samples\nEpoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r35/35 [==============================] - 5s 138ms/step - loss: 1.0078 - val_loss: 1.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss did not improve from 0.99881\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"Models/Weights/LSTM_weigths_spain.hdf5\", \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "for i, run in enumerate(run_list):\n",
    "    vae.fit(x=run, epochs=epochs,\n",
    "            batch_size=500,\n",
    "            callbacks=[checkpointer],\n",
    "            validation_data=(val_data, None))\n",
    "    vae.load_weights('Models/Weights/LSTM_weigths_spain.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(584, 100, 7)\n"
     ]
    }
   ],
   "source": [
    "pred = vae.predict(run_list[0])\n",
    "\n",
    "print(pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 122640 into shape (17500,7)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d5e941a05e9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m17500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 122640 into shape (17500,7)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "data = []\n",
    "for i in range(pred.shape[0]):\n",
    "    data.append(pred[i][:30])     \n",
    "\n",
    "data = np.array(data)\n",
    "data = data.reshape(17500, 7)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        seconds         x         y         z     speed  acceleration  \\\n0      0.378276 -0.653099  0.866958 -0.302582  0.032526     -0.002846   \n1      0.371704 -0.637209  0.893095 -0.286900  0.004704      0.037235   \n2      0.348831 -0.683477  0.856158 -0.279485  0.053193      0.017735   \n3      0.388676 -0.654716  0.845928 -0.290576  0.045179     -0.073679   \n4      0.383645 -0.659170  0.859524 -0.298999 -0.077745      0.075377   \n...         ...       ...       ...       ...       ...           ...   \n17495  0.962260 -1.121237  1.357784 -0.147709 -0.082481      0.038414   \n17496  0.963994 -1.125476  1.339069 -0.151385 -0.041723      0.029066   \n17497  0.966044 -1.108822  1.355389 -0.139897 -0.043795      0.010309   \n17498  0.951388 -1.129818  1.338037 -0.150493 -0.005272      0.022997   \n17499  0.970920 -1.099926  1.356977 -0.140783 -0.038879     -0.018608   \n\n        degrees  \n0     -0.395030  \n1     -0.391574  \n2     -0.393896  \n3     -0.405676  \n4     -0.393763  \n...         ...  \n17495  0.163855  \n17496  0.160382  \n17497  0.148591  \n17498  0.154719  \n17499  0.148743  \n\n[17500 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = ['seconds','x','y','z','speed','acceleration','degrees']\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame(data, columns=columns )\n",
    "print(data_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_df['degrees'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
