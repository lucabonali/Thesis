{
 "cells": [
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 1,
   "source": [
    "DATA PREPARATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54000, 4)\n(54000, 4) (5400, 4)\n(300, 180, 4)\n(30, 180, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "n_features = 4\n",
    "sequence_length = 180\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences_mix.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "boat_val = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequence_mix_val.csv\")\n",
    "boat_val = boat_val.drop(columns=[\"Unnamed: 0\"])\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "val_nom_data = scaler.fit_transform(boat_val)\n",
    "print(normal_data.shape, val_nom_data.shape)\n",
    "\n",
    "\n",
    "def prepare_sequences(data, batch_size):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0], batch_size):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "    sequences = np.array(samples)\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "    return trainX\n",
    "\n",
    "\n",
    "def prepare_data():    \n",
    "    trainX_nominal = prepare_sequences(normal_data,sequence_length) \n",
    "    print(trainX_nominal.shape)\n",
    "    \n",
    "    valX_nominal = prepare_sequences(val_nom_data,sequence_length)\n",
    "    print(valX_nominal.shape)\n",
    "\n",
    "    return trainX_nominal, valX_nominal\n",
    "\n",
    "\n",
    "trainX_nominal, valX_nominal = prepare_data()\n",
    "n_sequences = len(trainX_nominal)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "MODEL \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2DTranspose\n",
    "from keras.losses import mse\n",
    "\n",
    "intermediate_dimensions = 50\n",
    "latent_dim = 20\n",
    "filters = 50\n",
    "\n",
    "\n",
    "def Conv1DTranspose(input_tensor, filters, kernel_size,last, strides=2, padding='same'):\n",
    "        if last:\n",
    "            activation = 'linear'\n",
    "        else:\n",
    "            activation = 'relu'\n",
    "        x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), \n",
    "                            strides=(strides, 1), padding=padding,\n",
    "                            activation=activation)(x)\n",
    "        x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "def create_vae(verbose):\n",
    "    inputs = Input(shape=(None, n_features))\n",
    "    x = inputs\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = Conv1D(filters=filters,\n",
    "                   kernel_size=2,\n",
    "                   strides=2,\n",
    "                   padding='same')(x)\n",
    "    \n",
    "    shape = K.int_shape(x)\n",
    "    # x = Conv1D(filters=50,\n",
    "    #            kernel_size=2,\n",
    "    #            strides=2,\n",
    "    #            padding='same')(x)\n",
    "   \n",
    "    x = Reshape((-1,shape[1]*shape[2]))(x)\n",
    "    print(K.int_shape(x))\n",
    "    embeddings = Dense(intermediate_dimensions)(x)\n",
    "    \n",
    "    z_mean = Dense(latent_dim, name='z_mean',)(embeddings)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(embeddings)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    if verbose:\n",
    "        encoder.summary()\n",
    "    \n",
    "    latent_inputs = Input(shape=(latent_dim,), name='latent_inputs')\n",
    "    x = Dense(shape[1]*shape[2])(latent_inputs)\n",
    "    x = Reshape((shape[1], shape[2]))(x)\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = Conv1DTranspose(input_tensor=x,\n",
    "                            filters=filters,\n",
    "                            kernel_size=2,\n",
    "                            last=False,\n",
    "                            padding='same')\n",
    "    \n",
    "    \n",
    "    outputs = Conv1DTranspose(input_tensor=x,\n",
    "                              filters=n_features,\n",
    "                              kernel_size=2,\n",
    "                              strides=1,\n",
    "                              last=True,\n",
    "                              padding='same')\n",
    "    \n",
    "    decoder = Model(latent_inputs, outputs)\n",
    "    if verbose:\n",
    "        decoder.summary()\n",
    "    \n",
    "    outputs = decoder(encoder.outputs[2])\n",
    "    reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    loss = K.mean(reconstruction_loss)\n",
    "    \n",
    "    \n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "    vae.add_loss(loss)\n",
    "    \n",
    "    vae.compile(optimizer='rmsprop')\n",
    "    return (vae, encoder,decoder)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "MODEL TRAINING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Vae with 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'NoneType' and 'int'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-3c9b894ccab9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training Vae with '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mvaes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     vaes[i][0].fit(x=trainX_nominal,\n\u001b[0;32m     12\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-ef9f9d62dc50>\u001b[0m in \u001b[0;36mcreate_vae\u001b[1;34m(verbose)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m#            padding='same')(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mReshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintermediate_dimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'int'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"Models/Weights/Vae_conv1d_emb.hdf5\", \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "vaes = []\n",
    "epochs = [1]\n",
    "for i, epoch in enumerate(epochs):\n",
    "    print('Training Vae with ' + str(epoch))\n",
    "    vaes.append(create_vae(verbose=True))\n",
    "    vaes[i][0].fit(x=trainX_nominal,\n",
    "            epochs=epoch,\n",
    "            batch_size=sequence_length,\n",
    "            validation_data=(valX_nominal, None),\n",
    "            callbacks=[checkpointer],\n",
    "            verbose=0)\n",
    "    vaes[i][0].load_weights(\"Models/Weights/Vae_conv1d_emb.hdf5\")\n",
    "\n",
    "\n",
    "def train_generator():\n",
    "    while True:\n",
    "        sequence_length = np.random.randint(10, 100)\n",
    "        x_train = np.random.random((1000, sequence_length, 5))\n",
    "        # y_train will depend on past 5 timesteps of x\n",
    "        y_train = x_train[:, :, 0]\n",
    "        for i in range(1, 5):\n",
    "            y_train[:, i:] += x_train[:, :-i, i]\n",
    "        y_train = to_categorical(y_train > 2.5)\n",
    "        yield x_train, y_train\n",
    "\n",
    "model.fit_generator(train_generator(), epochs=epoch, verbose=1)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ENCODING AND RECONSTRUCTION ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (12,12,20) into shape (12,32,20)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-36cb008dba63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mencodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvaes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mencodings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX_nominal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtitles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Z_mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Z_log_var'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Z_Sampled'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    300\u001b[0m                     \u001b[0mouts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mouts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_start\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m                 \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (12,12,20) into shape (12,32,20)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "def return_mask(num, labels):\n",
    "        return np.squeeze(np.argwhere(labels == num))\n",
    "    \n",
    "    \n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "masks = [return_mask(num, labels)[:, 0] for num in range(0, 9)]\n",
    "encodings = []\n",
    "for t in vaes:\n",
    "    encodings.append(t[1].predict(trainX_nominal))\n",
    "\n",
    "titles = ['Z_mean','Z_log_var','Z_Sampled']\n",
    "def plot_encodings(unseen_point, unseen):\n",
    "    for enc in encodings:    \n",
    "        for i in range(3):\n",
    "            for mask in masks:\n",
    "                plt.scatter(x=enc[i][:, 0][mask], \n",
    "                            y=enc[i][:, 1][mask], alpha=0.5)\n",
    "            if unseen:    \n",
    "                plt.scatter(x=unseen_point[0], y=unseen_point[1])\n",
    "            plt.title(titles[i])\n",
    "            plt.legend(labels=np.arange(0, 9))\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "point = (0,0)\n",
    "plot_encodings(point, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 180, 4)\n(13, 180, 4)\n(16, 180, 4)\n(11, 180, 4)\n(15, 180, 4)\n(14, 180, 4)\n(12, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "runs = []\n",
    "for mask in masks:\n",
    "    run_for_class = trainX_nominal[mask]\n",
    "    print(run_for_class.shape)\n",
    "    runs.append(run_for_class)\n",
    "\n",
    "tit = ['350']\n",
    "for k,mod in enumerate(vaes):\n",
    "    for j in range(9):    \n",
    "        for i in runs[j]:\n",
    "            run = np.reshape(i, (1,sequence_length, n_features))\n",
    "            rec = mod[0].predict(run)\n",
    "            rec = np.reshape(rec, (len(trainX_nominal[0]), n_features))\n",
    "            reconstruction_df = pd.DataFrame(rec, columns=boat_csv.columns)\n",
    "            plt.plot(reconstruction_df[\"Lon\"], reconstruction_df[\"Lat\"])\n",
    "            plt.title(tit[k])\n",
    "            plt.show()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "UNSEEN ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135, 180, 4)\n"
     ]
    }
   ],
   "source": [
    "def return_mask(num, labels):\n",
    "        return np.squeeze(np.argwhere(labels == num))\n",
    "    \n",
    "\n",
    "boat_strange = pd.read_csv(\"Data/Boat_nominal_data/Boat_unseen.csv\")\n",
    "boat_strange = boat_strange.drop(columns=[\"Unnamed: 0\"])\n",
    "scaler = MinMaxScaler()\n",
    "boat_unseen_data = scaler.fit_transform(boat_strange)\n",
    "\n",
    "unseen_sequences = prepare_sequences(boat_unseen_data, 180)\n",
    "print(unseen_sequences.shape)\n",
    "  \n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_unseen_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "masks = [return_mask(num, labels)[:, 0] for num in range(0, 9)]\n",
    "encodings = []\n",
    "for t in vaes:\n",
    "    encodings.append(t[1].predict(unseen_sequences))\n",
    "    \n",
    "titles = ['Z_mean', 'Z_log_var', 'Z_Sampled']\n",
    "for enc in encodings:    \n",
    "    for i in range(3):\n",
    "        for mask in masks:\n",
    "            plt.scatter(x=enc[i][:, 0][mask], \n",
    "                        y=enc[i][:, 1][mask], alpha=0.5)\n",
    "        plt.title(titles[i])\n",
    "        plt.legend(labels=np.arange(0, 9))\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "UNSEEN RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n(15, 180, 4)\n"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "for mask in masks:\n",
    "    run_for_class = unseen_sequences[mask]\n",
    "    print(run_for_class.shape)\n",
    "    runs.append(run_for_class)\n",
    "\n",
    "tit = ['300']\n",
    "for k, mod in enumerate(vaes):\n",
    "    for j in range(9):    \n",
    "        for i in runs[j]:\n",
    "            run = np.reshape(i, (1, sequence_length, n_features))\n",
    "            rec = mod[0].predict(run)\n",
    "            rec = np.reshape(rec, (len(trainX_nominal[0]), n_features))\n",
    "            reconstruction_df = pd.DataFrame(rec, columns=boat_csv.columns)\n",
    "            plt.plot(reconstruction_df[\"Lon\"], reconstruction_df[\"Lat\"])\n",
    "            plt.title(tit[k])\n",
    "            plt.show()\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
