{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30720, 4)\n(30, 1024, 4)\n(3, 1024, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "n_features = 4\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences_mix.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "boat_val = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequence_mix_val.csv\")\n",
    "boat_val = boat_val.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "val_nom_data = scaler.fit_transform(boat_val)\n",
    "\n",
    "def prepare_sequences(data, batch_size):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0], batch_size):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "    sequences = np.array(samples)\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "    return trainX\n",
    "\n",
    "\n",
    "def prepare_data():    \n",
    "    trainX_nominal = prepare_sequences(normal_data,1024) \n",
    "    print(trainX_nominal.shape)\n",
    "    \n",
    "    valX_nominal = prepare_sequences(val_nom_data,1024)\n",
    "    print(valX_nominal.shape)\n",
    "\n",
    "    return trainX_nominal, valX_nominal\n",
    "\n",
    "trainX_nominal, valX_nominal = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\nCreating VAE with beta= 1.0\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 1024, 4)      0                                            \n__________________________________________________________________________________________________\nconv1d_153 (Conv1D)             (None, 1024, 50)     850         encoder_input[0][0]              \n__________________________________________________________________________________________________\nmax_pooling1d_141 (MaxPooling1D (None, 512, 50)      0           conv1d_153[0][0]                 \n__________________________________________________________________________________________________\nconv1d_154 (Conv1D)             (None, 512, 50)      10050       max_pooling1d_141[0][0]          \n__________________________________________________________________________________________________\nmax_pooling1d_142 (MaxPooling1D (None, 256, 50)      0           conv1d_154[0][0]                 \n__________________________________________________________________________________________________\nconv1d_155 (Conv1D)             (None, 256, 50)      10050       max_pooling1d_142[0][0]          \n__________________________________________________________________________________________________\nmax_pooling1d_143 (MaxPooling1D (None, 128, 50)      0           conv1d_155[0][0]                 \n__________________________________________________________________________________________________\nconv1d_156 (Conv1D)             (None, 128, 50)      10050       max_pooling1d_143[0][0]          \n__________________________________________________________________________________________________\nmax_pooling1d_144 (MaxPooling1D (None, 64, 50)       0           conv1d_156[0][0]                 \n__________________________________________________________________________________________________\nflatten_29 (Flatten)            (None, 3200)         0           max_pooling1d_144[0][0]          \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 20)           64020       flatten_29[0][0]                 \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 20)           64020       flatten_29[0][0]                 \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 20)           0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 159,040\nTrainable params: 159,040\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 20)                0         \n_________________________________________________________________\nDense_after_sampling (Dense) (None, 3200)              67200     \n_________________________________________________________________\nreshape_29 (Reshape)         (None, 64, 50)            0         \n_________________________________________________________________\nconv1d_157 (Conv1D)          (None, 64, 50)            10050     \n_________________________________________________________________\nup_sampling1d_5 (UpSampling1 (None, 128, 50)           0         \n_________________________________________________________________\nconv1d_158 (Conv1D)          (None, 128, 50)           10050     \n_________________________________________________________________\nup_sampling1d_6 (UpSampling1 (None, 256, 50)           0         \n_________________________________________________________________\nconv1d_159 (Conv1D)          (None, 256, 50)           10050     \n_________________________________________________________________\nup_sampling1d_7 (UpSampling1 (None, 512, 50)           0         \n_________________________________________________________________\nlambda_247 (Lambda)          (None, 512, 1, 50)        0         \n_________________________________________________________________\nconv2d_transpose_124 (Conv2D (None, 1024, 1, 4)        804       \n_________________________________________________________________\nlambda_248 (Lambda)          (None, 1024, 4)           0         \n=================================================================\nTotal params: 98,154\nTrainable params: 98,154\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import MaxPooling1D, MaxPool1D, Conv2DTranspose\n",
    "import tensorflow as tf\n",
    "\n",
    "input_shape = (1024, n_features)\n",
    "latent_dim = 20\n",
    "kernel_size = 4\n",
    "use_mse = True   \n",
    "load_weights = False\n",
    "random_weight = 1\n",
    "\n",
    "\n",
    "def create_vae(beta):\n",
    "    filters = 50\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    \n",
    "    def Conv1DTranspose(input_tensor, filters, kernel_size,last, strides=2, padding='same'):\n",
    "        if last:\n",
    "            activation = 'linear'\n",
    "        else:\n",
    "            activation = 'relu'\n",
    "        x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), \n",
    "                            strides=(strides, 1), padding=padding,\n",
    "                            activation=activation)(x)\n",
    "        x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = inputs\n",
    "    for i in range(4):\n",
    "        x = Conv1D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   padding='same',\n",
    "                   activation='relu')(x)\n",
    "        x = MaxPooling1D(2)(x)\n",
    "\n",
    "\n",
    "    shape = K.int_shape(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    encoder.summary()\n",
    "\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(shape[1] * shape[2], name='Dense_after_sampling')(latent_inputs)\n",
    "    x = Reshape((shape[1], shape[2]))(x)\n",
    "\n",
    "    filters = 50\n",
    "    for i in range(3):\n",
    "        x = Conv1D(\n",
    "                            filters=filters, \n",
    "                            kernel_size=kernel_size, \n",
    "                            padding='same')(x)\n",
    "        x = UpSampling1D(size=2)(x)\n",
    "\n",
    "\n",
    "    outputs = Conv1DTranspose(input_tensor=x,\n",
    "                              filters=n_features, \n",
    "                              kernel_size=4, padding='same',\n",
    "                              last=True)\n",
    "\n",
    "\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    decoder.summary()\n",
    "\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "    from keras.losses import mse, binary_crossentropy\n",
    "\n",
    "    reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "    kl_loss = (- 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)))\n",
    "    loss = reconstruction_loss + kl_loss\n",
    "    vae.add_loss(loss)\n",
    "\n",
    "    vae.compile(optimizer='rmsprop', metrics= ['accuracy'])\n",
    "\n",
    "    return (vae, encoder, decoder)\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "betas = np.linspace(1,1,1)\n",
    "print(betas)\n",
    "\n",
    "\n",
    "vaes = []\n",
    "for i, beta in enumerate(betas):\n",
    "    print(\"Creating VAE with beta=\", betas[i])\n",
    "    vaes.append(create_vae(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING Vae with beta = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30 samples, validate on 3 samples\nEpoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 12s 394ms/step - loss: 1.0321 - val_loss: 0.3628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00001: val_loss improved from inf to 0.36284, saving model to Models/Weights/Nominal_weights_vae.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 1.1216 - val_loss: 0.3463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00002: val_loss improved from 0.36284 to 0.34635, saving model to Models/Weights/Nominal_weights_vae.hdf5\nEpoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.9992 - val_loss: 0.3426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00003: val_loss improved from 0.34635 to 0.34255, saving model to Models/Weights/Nominal_weights_vae.hdf5\nEpoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.9733 - val_loss: 0.3338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00004: val_loss improved from 0.34255 to 0.33379, saving model to Models/Weights/Nominal_weights_vae.hdf5\nEpoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.9325 - val_loss: 0.3341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00005: val_loss did not improve from 0.33379\nEpoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.6160 - val_loss: 0.5987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00006: val_loss did not improve from 0.33379\nEpoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.8289 - val_loss: 0.3127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00007: val_loss improved from 0.33379 to 0.31272, saving model to Models/Weights/Nominal_weights_vae.hdf5\nEpoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.7910 - val_loss: 0.3454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00008: val_loss did not improve from 0.31272\nEpoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.7101 - val_loss: 0.3437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00009: val_loss did not improve from 0.31272\nEpoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.5243 - val_loss: 0.3972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00010: val_loss did not improve from 0.31272\nEpoch 11/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 15ms/step - loss: 0.4376 - val_loss: 0.3260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00011: val_loss did not improve from 0.31272\nEpoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.4616 - val_loss: 0.3259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00012: val_loss did not improve from 0.31272\nEpoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 11ms/step - loss: 0.3776 - val_loss: 0.3496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00013: val_loss did not improve from 0.31272\nEpoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.3313 - val_loss: 0.3181\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00014: val_loss did not improve from 0.31272\nEpoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.3721 - val_loss: 0.2959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00015: val_loss improved from 0.31272 to 0.29591, saving model to Models/Weights/Nominal_weights_vae.hdf5\nEpoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.3598 - val_loss: 0.3770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00016: val_loss did not improve from 0.29591\nEpoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.2956 - val_loss: 0.3718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00017: val_loss did not improve from 0.29591\nEpoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.3442 - val_loss: 0.3351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00018: val_loss did not improve from 0.29591\nEpoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.3995 - val_loss: 0.8381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00019: val_loss did not improve from 0.29591\nEpoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.2852 - val_loss: 0.4355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00020: val_loss did not improve from 0.29591\nEpoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.3617 - val_loss: 0.4008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00021: val_loss did not improve from 0.29591\nEpoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 18ms/step - loss: 0.3406 - val_loss: 0.3593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00022: val_loss did not improve from 0.29591\nEpoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 16ms/step - loss: 0.2658 - val_loss: 0.3355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00023: val_loss did not improve from 0.29591\nEpoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 16ms/step - loss: 0.2776 - val_loss: 0.3041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00024: val_loss did not improve from 0.29591\nEpoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.2508 - val_loss: 0.4684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00025: val_loss did not improve from 0.29591\nEpoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 18ms/step - loss: 0.3029 - val_loss: 0.3415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00026: val_loss did not improve from 0.29591\nEpoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 24ms/step - loss: 0.2130 - val_loss: 0.4378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00027: val_loss did not improve from 0.29591\nEpoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 23ms/step - loss: 0.2845 - val_loss: 0.3253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00028: val_loss did not improve from 0.29591\nEpoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 19ms/step - loss: 0.2912 - val_loss: 0.3824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00029: val_loss did not improve from 0.29591\nEpoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 19ms/step - loss: 0.2686 - val_loss: 0.4233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00030: val_loss did not improve from 0.29591\nEpoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 19ms/step - loss: 0.3153 - val_loss: 0.3290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00031: val_loss did not improve from 0.29591\nEpoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 23ms/step - loss: 0.2721 - val_loss: 0.6084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00032: val_loss did not improve from 0.29591\nEpoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.2679 - val_loss: 0.3446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00033: val_loss did not improve from 0.29591\nEpoch 34/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 11ms/step - loss: 0.3022 - val_loss: 0.6472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00034: val_loss did not improve from 0.29591\nEpoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 11ms/step - loss: 0.3354 - val_loss: 0.2689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00035: val_loss improved from 0.29591 to 0.26889, saving model to Models/Weights/Nominal_weights_vae.hdf5\nEpoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.5049 - val_loss: 0.2819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00036: val_loss did not improve from 0.26889\nEpoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 15ms/step - loss: 0.2480 - val_loss: 0.3637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00037: val_loss did not improve from 0.26889\nEpoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.2482 - val_loss: 0.3043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00038: val_loss did not improve from 0.26889\nEpoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.2249 - val_loss: 0.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00039: val_loss did not improve from 0.26889\nEpoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 15ms/step - loss: 0.2060 - val_loss: 0.5053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00040: val_loss did not improve from 0.26889\nEpoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 29ms/step - loss: 0.2226 - val_loss: 0.4630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00041: val_loss did not improve from 0.26889\nEpoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 26ms/step - loss: 0.2094 - val_loss: 0.3626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00042: val_loss did not improve from 0.26889\nEpoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 17ms/step - loss: 0.2151 - val_loss: 0.6593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00043: val_loss did not improve from 0.26889\nEpoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 22ms/step - loss: 0.2353 - val_loss: 0.4957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00044: val_loss did not improve from 0.26889\nEpoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 19ms/step - loss: 0.1739 - val_loss: 0.3765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00045: val_loss did not improve from 0.26889\nEpoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 25ms/step - loss: 0.1797 - val_loss: 0.5557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00046: val_loss did not improve from 0.26889\nEpoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 18ms/step - loss: 0.2028 - val_loss: 0.6940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00047: val_loss did not improve from 0.26889\nEpoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 18ms/step - loss: 0.2171 - val_loss: 0.3956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00048: val_loss did not improve from 0.26889\nEpoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.2105 - val_loss: 0.5204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00049: val_loss did not improve from 0.26889\nEpoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.1721 - val_loss: 0.4414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00050: val_loss did not improve from 0.26889\nEpoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.1790 - val_loss: 0.4506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00051: val_loss did not improve from 0.26889\nEpoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.1732 - val_loss: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00052: val_loss did not improve from 0.26889\nEpoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.2393 - val_loss: 0.5046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00053: val_loss did not improve from 0.26889\nEpoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.1966 - val_loss: 0.5856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00054: val_loss did not improve from 0.26889\nEpoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.1462 - val_loss: 0.4795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00055: val_loss did not improve from 0.26889\nEpoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 15ms/step - loss: 0.1616 - val_loss: 0.5508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00056: val_loss did not improve from 0.26889\nEpoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1600 - val_loss: 0.4162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00057: val_loss did not improve from 0.26889\nEpoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.1561 - val_loss: 0.5356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00058: val_loss did not improve from 0.26889\nEpoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1634 - val_loss: 0.4675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00059: val_loss did not improve from 0.26889\nEpoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 15ms/step - loss: 0.1397 - val_loss: 0.5809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00060: val_loss did not improve from 0.26889\nEpoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.1328 - val_loss: 0.5468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00061: val_loss did not improve from 0.26889\nEpoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1300 - val_loss: 0.6820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00062: val_loss did not improve from 0.26889\nEpoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 24ms/step - loss: 0.1364 - val_loss: 0.5712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00063: val_loss did not improve from 0.26889\nEpoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 18ms/step - loss: 0.1395 - val_loss: 0.5407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00064: val_loss did not improve from 0.26889\nEpoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 24ms/step - loss: 0.1198 - val_loss: 0.5776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00065: val_loss did not improve from 0.26889\nEpoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 22ms/step - loss: 0.1121 - val_loss: 0.5428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00066: val_loss did not improve from 0.26889\nEpoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 28ms/step - loss: 0.1003 - val_loss: 0.6057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00067: val_loss did not improve from 0.26889\nEpoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 23ms/step - loss: 0.1395 - val_loss: 0.5810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00068: val_loss did not improve from 0.26889\nEpoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 23ms/step - loss: 0.1407 - val_loss: 0.6608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00069: val_loss did not improve from 0.26889\nEpoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 22ms/step - loss: 0.1472 - val_loss: 0.5380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00070: val_loss did not improve from 0.26889\nEpoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 1s 17ms/step - loss: 0.1335 - val_loss: 0.6163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00071: val_loss did not improve from 0.26889\nEpoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.1419 - val_loss: 0.6504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00072: val_loss did not improve from 0.26889\nEpoch 73/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.1324 - val_loss: 0.6568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00073: val_loss did not improve from 0.26889\nEpoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 11ms/step - loss: 0.1341 - val_loss: 0.5305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00074: val_loss did not improve from 0.26889\nEpoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1237 - val_loss: 0.6636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00075: val_loss did not improve from 0.26889\nEpoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1256 - val_loss: 0.5623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00076: val_loss did not improve from 0.26889\nEpoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 15ms/step - loss: 0.1048 - val_loss: 0.6529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00077: val_loss did not improve from 0.26889\nEpoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.1035 - val_loss: 0.6779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00078: val_loss did not improve from 0.26889\nEpoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1004 - val_loss: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00079: val_loss did not improve from 0.26889\nEpoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.1071 - val_loss: 0.7935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00080: val_loss did not improve from 0.26889\nEpoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1278 - val_loss: 0.4499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00081: val_loss did not improve from 0.26889\nEpoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1362 - val_loss: 0.8238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00082: val_loss did not improve from 0.26889\nEpoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.1103 - val_loss: 0.5507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00083: val_loss did not improve from 0.26889\nEpoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1208 - val_loss: 0.6954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00084: val_loss did not improve from 0.26889\nEpoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.0893 - val_loss: 0.6364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00085: val_loss did not improve from 0.26889\nEpoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.0820 - val_loss: 0.6609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00086: val_loss did not improve from 0.26889\nEpoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.0793 - val_loss: 0.7077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00087: val_loss did not improve from 0.26889\nEpoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.0791 - val_loss: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00088: val_loss did not improve from 0.26889\nEpoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.0769 - val_loss: 0.6157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00089: val_loss did not improve from 0.26889\nEpoch 90/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.0705 - val_loss: 0.6353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00090: val_loss did not improve from 0.26889\nEpoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.0748 - val_loss: 0.6485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00091: val_loss did not improve from 0.26889\nEpoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 12ms/step - loss: 0.0654 - val_loss: 0.6311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00092: val_loss did not improve from 0.26889\nEpoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.0909 - val_loss: 0.7209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00093: val_loss did not improve from 0.26889\nEpoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1043 - val_loss: 0.5772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00094: val_loss did not improve from 0.26889\nEpoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.1123 - val_loss: 0.6869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00095: val_loss did not improve from 0.26889\nEpoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.0943 - val_loss: 0.6084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00096: val_loss did not improve from 0.26889\nEpoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.0869 - val_loss: 0.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00097: val_loss did not improve from 0.26889\nEpoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.0716 - val_loss: 0.6338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00098: val_loss did not improve from 0.26889\nEpoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 13ms/step - loss: 0.0607 - val_loss: 0.7025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00099: val_loss did not improve from 0.26889\nEpoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r30/30 [==============================] - 0s 14ms/step - loss: 0.0618 - val_loss: 0.6354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nEpoch 00100: val_loss did not improve from 0.26889\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(vaes)):\n",
    "    checkpointer = ModelCheckpoint(filepath=\"Models/Weights/Nominal_weights_vae.hdf5\",\n",
    "                                   verbose=1, save_best_only=True)\n",
    "    print(\"FITTING Vae with beta =\", betas[i])\n",
    "    vaes[i][0].fit(x=trainX_nominal,\n",
    "            epochs=100,\n",
    "            batch_size=1024,\n",
    "            validation_data=(valX_nominal,None),\n",
    "            callbacks=[checkpointer])\n",
    "    vaes[i][0].load_weights('Models/Weights/Nominal_weights_vae.hdf5')\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ENCODED ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14345892 0.13982122]\n"
     ]
    }
   ],
   "source": [
    "def return_mask(num, labels):\n",
    "    return np.squeeze(np.argwhere(labels == num))\n",
    "\n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "masks = [return_mask(num,labels)[:,0] for num in range(0,9)]\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model_index = 0\n",
    "encodings = []\n",
    "\n",
    "for i in vaes:\n",
    "    encodings.append(i[1].predict(trainX_nominal))\n",
    "\n",
    "def check_z_sampling(encoded_values):\n",
    "    m = encoded_values[0]\n",
    "    var = np.exp(0.5*encoded_values[1])\n",
    "    eps = np.random.normal(0,1,latent_dim)\n",
    "    \n",
    "    sampled = []\n",
    "    index = 0\n",
    "    var_zero = np.zeros(10)\n",
    "    for means in m:\n",
    "        sample = means+var[index]*eps\n",
    "        #sample = means+var_zero*eps \n",
    "        sampled.append(sample)\n",
    "        index += 1\n",
    "    \n",
    "    sampled = np.array(sampled)\n",
    "    return sampled\n",
    "\n",
    "    \n",
    "latent_values = check_z_sampling(encodings[0])\n",
    "scaler = StandardScaler()\n",
    "enc_input = scaler.fit_transform(encodings[0][1]) #encodings[0][2] for sampled embeddings\n",
    "pca = PCA(2)\n",
    "principalComponents = pca.fit_transform(enc_input)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "def get_legend_labels(masks):\n",
    "    labs = []\n",
    "    for i in masks:\n",
    "        print(i)\n",
    "    return labs\n",
    "\n",
    "\n",
    "def plot_pca(): \n",
    "    x_val = []\n",
    "    y_val= []\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    for mask in masks:\n",
    "        plt.scatter(x=x_val[mask], y=y_val[mask], alpha=0.5)\n",
    "\n",
    "    plt.legend(labels=np.arange(0,9))\n",
    "    plt.show()\n",
    "plot_pca()\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "UNSEEN DATA PLOTTING IN PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat_strange = pd.read_csv(\"Data/Boat_nominal_data/Boat_unseen.csv\")\n",
    "boat_strange = boat_strange.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = MinMaxScaler()\n",
    "boat_unseen_data = scaler.fit_transform(boat_strange)\n",
    "#boat_unseen_data = np.array(boat_strange)\n",
    "boat_unseen_data = np.reshape(boat_unseen_data, (1,len(boat_unseen_data),n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22333093,  0.09127659]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_encoding = vaes[0][1].predict(boat_unseen_data)\n",
    "pca.transform(unseen_encoding[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "CLUSTERING OF LATENT SPACE and Reconstruction Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 20)\n(9, 20)\n(15, 20)\n(7, 20)\n(13, 20)\n(7, 20)\n(9, 20)\n(6, 20)\n(7, 20)\n"
     ]
    }
   ],
   "source": [
    "def reconstruct_runs(run):\n",
    "    run = np.reshape(run, (1, latent_dim))\n",
    "    reconstruction = vaes[0][2].predict(run)\n",
    "    reconstruction = np.reshape(reconstruction, \n",
    "                                (len(trainX_nominal[0]), n_features))\n",
    "    reconstruction_df = pd.DataFrame(reconstruction, columns=boat_csv.columns)\n",
    "    \n",
    "    plt.plot(reconstruction_df[\"Lon\"], reconstruction_df[\"Lat\"])\n",
    "    #plt.savefig(\"Imgs/Latent_reconstruction/\"+str(title)+\".png\")\n",
    "    plt.show()\n",
    "    #plt.clf()\n",
    "\n",
    "\n",
    "runs = []\n",
    "for mask in masks:\n",
    "    run_for_class = latent_values[mask]\n",
    "    print(run_for_class.shape)\n",
    "    runs.append(run_for_class)\n",
    "\n",
    "\n",
    "\n",
    "for r in runs:    \n",
    "    for sample in r:\n",
    "        reconstruct_runs(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169, 1024, 4)\n(15, 1024, 4)\n(19, 1024, 4)\n(16, 1024, 4)\n(15, 1024, 4)\n(19, 1024, 4)\n(13, 1024, 4)\n(18, 1024, 4)\n(16, 1024, 4)\n"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "for mask in masks:\n",
    "    run_for_class = trainX_nominal[mask]\n",
    "    print(run_for_class.shape)\n",
    "    runs.append(run_for_class)\n",
    "    \n",
    "for i in runs[0]:\n",
    "    run = np.reshape(i, (1, 1024,4))\n",
    "    rec = vaes[0][0].predict(run)\n",
    "    rec = np.reshape(rec, \n",
    "                                (len(trainX_nominal[0]), n_features))\n",
    "    reconstruction_df = pd.DataFrame(rec, columns=boat_csv.columns)\n",
    "    \n",
    "    plt.plot(reconstruction_df[\"Lon\"], reconstruction_df[\"Lat\"])\n",
    "    #plt.savefig(\"Imgs/Latent_reconstruction/\"+str(title)+\".png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "PCA and TSNE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encodings = []\n",
    "\n",
    "for i in vaes:\n",
    "    encodings.append(i[1].predict(trainX_nominal))\n",
    "\n",
    "def check_z_sampling(encoded_values):\n",
    "    m = encoded_values[0]\n",
    "    var = np.exp(0.5*encoded_values[1])\n",
    "    eps = np.random.normal(0,1,latent_dim)\n",
    "    \n",
    "    sampled = []\n",
    "    index = 0\n",
    "    var_zero = np.zeros(10)\n",
    "    for means in m:\n",
    "        sample = means+var[index]*eps\n",
    "        #sample = means+var_zero*eps \n",
    "        \n",
    "        sampled.append(sample)\n",
    "        index +=1\n",
    "    \n",
    "    sampled = np.array(sampled)\n",
    "    return sampled\n",
    "    \n",
    "values = check_z_sampling(encodings[0])\n",
    "\n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "mat_mask = np.array([labels for i in range(latent_dim)])\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "labels = np.array(pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")['label']) \n",
    "nominals = np.squeeze(np.argwhere(labels==1))\n",
    "anomalous = np.squeeze(np.argwhere(labels==0))\n",
    "print(type(nominals), type(nominals[0]))\n",
    "\n",
    "model_index = 0\n",
    "\n",
    "titles = [\"Mean\", \"Std\", \"Sampled\"]\n",
    "\n",
    "for i in encodings[model_index]:\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(i)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    x_val = []\n",
    "    y_val=[]\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    \n",
    "    plt.scatter(x=x_val[nominals],y=y_val[nominals], alpha=0.5)\n",
    "    plt.scatter(x=x_val[anomalous],y=y_val[anomalous], alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne(data, title):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    \n",
    "    tsne_obj= tsne.fit_transform(data)\n",
    "    tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                            'Y':tsne_obj[:,1],\n",
    "                            })\n",
    "    \n",
    "    plt.scatter(x=tsne_df[\"X\"][nominals],\n",
    "                y=tsne_df[\"Y\"][nominals], alpha=0.5)\n",
    "    plt.scatter(x=tsne_df[\"X\"][anomalous],\n",
    "                y=tsne_df[\"Y\"][anomalous], alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return tsne_df\n",
    "\n",
    "for i, encode in enumerate(encodings[model_index]):\n",
    "    tsne_enc_nom_df = tsne(encode, titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_from_latent_space(xCoord, yCoord):\n",
    "    point = np.array([xCoord,yCoord])\n",
    "    latent_point = pca.inverse_transform(point)\n",
    "    return np.reshape(latent_point,(1, latent_dim))\n",
    "\n",
    "def visualize_reconstruction(reconstructed_run, title):\n",
    "    plt.plot(reconstructed_run[\"Lon\"], reconstructed_run[\"Lat\"])\n",
    "    plt.title(title)\n",
    "    \n",
    "    # plt.plot(reconstructed_run[\"Sin\"])\n",
    "    # plt.plot(reconstructed_run[\"Cosin\"])\n",
    "    # plt.title(title)\n",
    "    plt.savefig(\"Imgs/Latent_analysis/\"+str(title)+\".png\")\n",
    "    plt.clf()\n",
    "    # plt.show()\n",
    "\n",
    "X,Y = np.mgrid[-5:5:0.5, -5:5:0.5]\n",
    "XY = np.vstack((X.flatten(), Y.flatten())).T\n",
    "print(XY.shape)\n",
    "\n",
    "for i,p in enumerate(XY):    \n",
    "    point = sample_from_latent_space(p[0],p[1])\n",
    "    reconstructed = np.reshape(vaes[model_index][2].predict(point), (len(trainX_nominal[0]),n_features))\n",
    "    visualize_reconstruction(pd.DataFrame(reconstructed, columns=boat_csv.columns), \n",
    "                             title=str(i)+str(p))\n",
    "\n",
    "# line = np.arange(-10, 10, 0.5)\n",
    "# \n",
    "# for i,point2d in enumerate(line):\n",
    "#     point = sample_from_latent_space(point2d,point2d)\n",
    "#     reconstructed = np.reshape(vaes[model_index][2].predict(point), (len(trainX_nominal[0]),n_features))\n",
    "#     visualize_reconstruction(pd.DataFrame(reconstructed, columns=boat_csv.columns), \n",
    "#                              title=point2d)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "OLD STUFF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_neuron_values(encoding):\n",
    "    neurons_m = []\n",
    "    neurons_var = []\n",
    "    for i in range(latent_dim):\n",
    "        neurons_m.append(encoding[0][:, i])\n",
    "        neurons_var.append(encoding[1][:, i])\n",
    "    \n",
    "    for i in range(latent_dim):\n",
    "        plt.plot(neurons_m[i])\n",
    "    plt.show()\n",
    "    \n",
    "    return (neurons_m, neurons_var)\n",
    "\n",
    "neuron_values = []\n",
    "for i in encodings:\n",
    " neuron_values.append(get_neuron_values(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nominal_parameters(n_m, n_var):\n",
    "    neuron_avg_nom = np.ma.array(n_m, mask=np.logical_not(mat_mask))\n",
    "    neuron_avg_nom = np.mean(neuron_avg_nom, axis=1)\n",
    "    neuron_var_nom = np.ma.array(n_var, mask=np.logical_not(mat_mask))\n",
    "    neuron_var_nom = np.mean(neuron_var_nom, axis=1)\n",
    "     \n",
    "    neuron_avg_anom = np.ma.array(n_m, mask=mat_mask)\n",
    "    neuron_avg_anom = np.mean(neuron_avg_anom, axis=1)\n",
    "    neuron_var_anom = np.ma.array(n_var, mask=mat_mask)\n",
    "    neuron_var_anom = np.mean(neuron_var_anom, axis=1)\n",
    "    \n",
    "    return (neuron_avg_nom, neuron_var_nom, neuron_avg_anom, neuron_var_anom)\n",
    "\n",
    "enc_values = []\n",
    "for i in neuron_values:\n",
    "    enc_values.append(nominal_parameters(i[0], i[1]))\n",
    "print(len(enc_values))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "DIFFERENCES IN ENCODING OF NOMINAL AND ANOMALOUS BEHAVIOUR VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_difference(avg_n, var_n, avg_an, var_an):\n",
    "    plt.plot(avg_n)\n",
    "    plt.plot(avg_an)\n",
    "    plt.title(\"MEAN\")\n",
    "    plt.show()\n",
    "    \n",
    "    # plt.plot(var_n)\n",
    "    # plt.plot(var_an)\n",
    "    # plt.title(\"STD\")\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "for i in enc_values:\n",
    "    visualize_difference(i[0], i[1], i[2], i[3])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ANALYSIS OF ENCODING AND DECODING OF THE ANOMALOUS RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08811088  0.1255463   0.01701382 -0.08566583  0.1815099  -0.00088965] [ 0.16391774  0.00667964 -0.08026419 -0.01931977 -0.09087465  0.04685581]\n"
     ]
    }
   ],
   "source": [
    "boat_anom_csv = pd.read_csv(\"Data/Boat_anom_sequence.csv\")\n",
    "boat_anom_csv = boat_anom_csv.drop(columns=[\"Unnamed: 0\",\"Speed\", \"Acceleration\",\n",
    "                                            \"M0C\", \"M1C\"])\n",
    "anom_data_norm = scaler.fit_transform(boat_anom_csv)\n",
    "anom_data_norm = np.reshape(anom_data_norm, (1, len(anom_data_norm), n_features))\n",
    "anom_data_encoding = np.squeeze(encoder.predict(anom_data_norm))\n",
    "\n",
    "anom_means = anom_data_encoding[0]\n",
    "anom_var = anom_data_encoding[1]\n",
    "print(anom_means, anom_var)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "SAMPLING FROM VALUES OF THE LATENT SPACE AND CHANGING ONLY ONE, \n",
    "THEN CHECK THE RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_sampled(sample_nom, sample_anom):\n",
    "    plt.plot(sample_nom)    \n",
    "    plt.plot(sample_anom)\n",
    "    plt.title(\"SAMPLED DIFFERENCES\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def reconstruct_from_latent_vectors(latents, model_index):\n",
    "    latents = np.reshape(latents, (1,len(latents)))\n",
    "    run = vaes[model_index][2].predict(latents)\n",
    "    run_df = pd.DataFrame(run[0], columns=boat_csv.columns)\n",
    "    \n",
    "    plt.plot(run_df[\"Lon\"])#, run_df[\"Lat\"])\n",
    "    plt.plot(run_df[\"Lat\"])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "epsilon = np.random.normal(0,1)\n",
    "sample_nominal = enc_values[0][0] + np.exp(0.5*enc_values[0][1])*epsilon\n",
    "sample_anomalous = enc_values[0][2] + np.exp(0.5*enc_values[0][3])*epsilon\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = np.linspace(0,6,50)\n",
    "neur = 0\n",
    "for i in changes:\n",
    "    sample_nominal[neur] = sample_anomalous[neur]*i\n",
    "    #visualize_latent_sampled(sample_nominal, sample_anomalous)\n",
    "    reconstruct_from_latent_vectors(sample_nominal,0)\n",
    "# reconstruct_from_latent_vectors(sample_anomalous)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "VISUALIZATION of ENCODED VALUES OF MEAN AND SIGMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "labels = np.array(pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")['label']) \n",
    "nominals = np.squeeze(np.argwhere(labels==1))\n",
    "anomalous = np.squeeze(np.argwhere(labels==0))\n",
    "print(type(nominals), type(nominals[0]))\n",
    "\n",
    "model_index = 0\n",
    "\n",
    "titles = [\"Mean\", \"Std\", \"Sampled\"]\n",
    "\n",
    "for i in encodings[model_index]:\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(i)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    x_val = []\n",
    "    y_val=[]\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    \n",
    "    plt.scatter(x=x_val[nominals],y=y_val[nominals], alpha=0.5)\n",
    "    plt.scatter(x=x_val[anomalous],y=y_val[anomalous], alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne(data, title):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    \n",
    "    tsne_obj= tsne.fit_transform(data)\n",
    "    tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                            'Y':tsne_obj[:,1],\n",
    "                            })\n",
    "    \n",
    "    plt.scatter(x=tsne_df[\"X\"][nominals],\n",
    "                y=tsne_df[\"Y\"][nominals], alpha=0.5)\n",
    "    plt.scatter(x=tsne_df[\"X\"][anomalous],\n",
    "                y=tsne_df[\"Y\"][anomalous], alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return tsne_df\n",
    "\n",
    "for i, encode in enumerate(encodings[model_index]):\n",
    "    tsne_enc_nom_df = tsne(encode, titles[i])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ANALYZING SPACE OF PCA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    }
   ],
   "source": [
    "def sample_from_latent_space(xCoord, yCoord):\n",
    "    point = np.array([xCoord,yCoord])\n",
    "    latent_point = pca.inverse_transform(point)\n",
    "    return np.reshape(latent_point,(1, latent_dim))\n",
    "\n",
    "def visualize_reconstruction(reconstructed_run, title):\n",
    "    plt.plot(reconstructed_run[\"Lon\"], reconstructed_run[\"Lat\"])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    # plt.plot(reconstructed_run[\"Sin\"])\n",
    "    # plt.plot(reconstructed_run[\"Cosin\"])\n",
    "    # plt.show()\n",
    "\n",
    "line = np.arange(-6, 6, 0.5)\n",
    "X,Y = np.mgrid[-4:4:0.5, -4:4:0.5]\n",
    "XY = np.vstack((X.flatten(), Y.flatten())).T\n",
    "print(XY.shape)\n",
    "\n",
    "for p in XY:    \n",
    "    point = sample_from_latent_space(p[1],p[0])\n",
    "    reconstructed = np.reshape(vaes[model_index][2].predict(point), (len(trainX_nominal[0]),n_features))\n",
    "    visualize_reconstruction(pd.DataFrame(reconstructed, columns=boat_csv.columns), \n",
    "                             title=p)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms\")\n",
    "dend_nom = shc.dendrogram(shc.linkage(tsne_enc_nom_df, method='ward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "cluster = AgglomerativeClustering(n_clusters=n_clusters, \n",
    "                                  affinity='euclidean',\n",
    "                                  linkage='ward')\n",
    "cl_nom = cluster.fit_predict(tsne_enc_nom_df)\n",
    "print(cl_nom)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_nom = []\n",
    "y_val_nom = []\n",
    "\n",
    "x_val_anom = []\n",
    "y_val_anom = []\n",
    "for i, xCoord in enumerate(tsne_enc_nom_df['X']):\n",
    "    if cl_nom[i] == 0:\n",
    "        x_val_nom.append(xCoord)\n",
    "        y_val_nom.append(tsne_enc_nom_df['Y'][i])\n",
    "    else:\n",
    "        x_val_anom.append(xCoord)\n",
    "        y_val_anom.append(tsne_enc_nom_df['Y'][i])\n",
    "\n",
    "plt.scatter(x=x_val_nom,\n",
    "            y=y_val_nom, alpha=0.5)\n",
    "plt.scatter(x=x_val_anom,\n",
    "            y=y_val_anom, alpha=0.5)\n",
    "plt.show()\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
