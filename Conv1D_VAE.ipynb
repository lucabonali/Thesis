{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(430992, 8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72600, 8)\n(13200, 8)\n(656, 656, 8)\n(10, 656, 8)\n(10, 6600, 8)\n(1, 6600, 8)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "\n",
    "# Setup the network parameters:\n",
    "beta = 5\n",
    "n_features = 8\n",
    "\n",
    "\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_nominal_long.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "boat_val = pd.read_csv(\"Data/Boat_nominal_data/Boat_nom_validation.csv\")\n",
    "boat_val = boat_val.drop(columns=[\"Unnamed: 0\"])\n",
    "scaler = StandardScaler()\n",
    "val_nom_data = scaler.fit_transform(boat_val)\n",
    "\n",
    "\n",
    "boat_anom_csv = pd.read_csv(\"Data/Boat_anomalous_big.csv\")\n",
    "boat_anom_csv= boat_anom_csv.drop(columns=[\"Unnamed: 0\"])    \n",
    "scaler = StandardScaler()\n",
    "anomalous_data = scaler.fit_transform(boat_anom_csv)\n",
    "print(anomalous_data.shape)\n",
    "\n",
    "boat_anom_val_csv = pd.read_csv(\"Data/Boat_anomalous_validation.csv\")\n",
    "boat_anom_val_csv= boat_anom_val_csv.drop(columns=[\"Unnamed: 0\"])    \n",
    "scaler = StandardScaler()\n",
    "anomalous_val_data = scaler.fit_transform(boat_anom_val_csv)\n",
    "print(anomalous_val_data.shape)\n",
    "\n",
    "def prepare_sequences(data, batch_size, interval):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0]- batch_size, interval):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "\n",
    "    sequences = np.array(samples)\n",
    "\n",
    "    # Batch size (Number of samples time steps and number of features\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "\n",
    "    return trainX\n",
    "\n",
    "\n",
    "def prepare_data():    \n",
    "    trainX_nominal = prepare_sequences(normal_data,656,656) \n",
    "    print(trainX_nominal.shape)\n",
    "    \n",
    "    valX_nominal = prepare_sequences(val_nom_data, 656,656)\n",
    "    print(valX_nominal.shape)\n",
    "    \n",
    "    trainX_anomalous = prepare_sequences(anomalous_data,6600,6600)\n",
    "    print(trainX_anomalous.shape)  \n",
    "    \n",
    "    valX_anom = prepare_sequences(anomalous_val_data,6600,6600)\n",
    "    print(valX_anom.shape)\n",
    "\n",
    "    return trainX_nominal, valX_nominal, trainX_anomalous, valX_anom\n",
    "\n",
    "\n",
    "\n",
    "trainX_nominal, valX_nominal, trainX_anomalous, valX_anom = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 656, 8)       0                                            \n__________________________________________________________________________________________________\nconv1d_123 (Conv1D)             (None, 328, 300)     17100       encoder_input[0][0]              \n__________________________________________________________________________________________________\nconv1d_124 (Conv1D)             (None, 164, 150)     315150      conv1d_123[0][0]                 \n__________________________________________________________________________________________________\nconv1d_125 (Conv1D)             (None, 82, 75)       78825       conv1d_124[0][0]                 \n__________________________________________________________________________________________________\nconv1d_126 (Conv1D)             (None, 41, 37)       19462       conv1d_125[0][0]                 \n__________________________________________________________________________________________________\nflatten_30 (Flatten)            (None, 1517)         0           conv1d_126[0][0]                 \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 20)           30360       flatten_30[0][0]                 \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 20)           30360       flatten_30[0][0]                 \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 20)           0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 491,257\nTrainable params: 491,257\nNon-trainable params: 0\n__________________________________________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 20)                0         \n_________________________________________________________________\nDense_after_sampling (Dense) (None, 1517)              31857     \n_________________________________________________________________\nreshape_29 (Reshape)         (None, 41, 37)            0         \n_________________________________________________________________\nup_sampling1d_84 (UpSampling (None, 82, 37)            0         \n_________________________________________________________________\nup_sampling1d_85 (UpSampling (None, 164, 37)           0         \n_________________________________________________________________\nup_sampling1d_86 (UpSampling (None, 328, 37)           0         \n_________________________________________________________________\nup_sampling1d_87 (UpSampling (None, 656, 37)           0         \n_________________________________________________________________\nconv1d_127 (Conv1D)          (None, 656, 8)            2080      \n=================================================================\nTotal params: 33,937\nTrainable params: 33,937\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import objectives\n",
    "from keras.layers import RepeatVector\n",
    "\n",
    "input_shape = (656, 8)\n",
    "kernel_size = 7\n",
    "filters = 300\n",
    "latent_dim = 20\n",
    "epochs = 30\n",
    "use_mse = True\n",
    "load_weights = False\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for i in range(4):\n",
    "    x = Conv1D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               padding='same')(x)\n",
    "    filters = int(filters / 2)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2], name='Dense_after_sampling')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2]))(x)\n",
    "\n",
    "for i in range(4):\n",
    "    filters = filters*2\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "\n",
    "outputs = Conv1D(filters=8, kernel_size=7, padding='same')(x)\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "from keras.losses import mse\n",
    "\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n",
    "loss = reconstruction_loss + kl_loss\n",
    "vae.add_loss(loss)\n",
    "\n",
    "vae.compile(optimizer='rmsprop', metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 656 samples, validate on 10 samples\nEpoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 17s 26ms/step - loss: 1.2633 - val_loss: 19.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 18.9299 - val_loss: 9.7245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 9.5625 - val_loss: 8.7206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 8.6571 - val_loss: 3.1761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 3.1556 - val_loss: 1.4645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.4612 - val_loss: 1.2733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 11s 16ms/step - loss: 1.2906 - val_loss: 1.1887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.2085 - val_loss: 1.1529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.1537 - val_loss: 1.1149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.1128 - val_loss: 1.0886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.0812 - val_loss: 1.0508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.0574 - val_loss: 1.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.0341 - val_loss: 1.0351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 1.0179 - val_loss: 1.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r656/656 [==============================] - 9s 14ms/step - loss: 0.9995 - val_loss: 1.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-552f06a56834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m vae.fit(x=trainX_nominal, epochs=50, \n\u001b[0;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m656\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         validation_data=(valX_nominal,None))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "vae.fit(x=trainX_nominal, epochs=50, \n",
    "        batch_size=656,\n",
    "        validation_data=(valX_nominal,None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(656, 656, 8)\n"
     ]
    }
   ],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(656, 656, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_conv = 7\n",
    "latent_dim = 10\n",
    "intermediate_dim = 200\n",
    "epsilon_std = 1.0\n",
    "epochs = 5\n",
    "\n",
    "x = Input(batch_shape=(None ,656, n_features))\n",
    "conv_1 = Conv1D(filters=200,\n",
    "                kernel_size=num_conv,\n",
    "                padding='same')(x)\n",
    "conv_2 = Conv1D(filters=100,\n",
    "                kernel_size=num_conv,\n",
    "                padding='same')(conv_1)\n",
    "flat = Flatten()(conv_2) # Since we are passing flat data anyway, we probably don't need this.\n",
    "hidden = Dense(intermediate_dim,name=\"Dense_Flatten\", activation='relu')(flat)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(hidden)\n",
    "z_log_var = Dense(latent_dim, name='z_var')(hidden)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(656,latent_dim),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_var- K.square(z_mean) - K.exp(z_log_var)) * epsilon \n",
    "    # the original VAE divides z_log_var with two -- why?\n",
    "\n",
    "\n",
    "z = Lambda(sampling,input_shape=(656,latent_dim), \n",
    "           output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "decoder_h = Dense(intermediate_dim, name='dense_after_sampling')\n",
    "decoder_mean = Dense(n_features,name=\"decoder_output\")\n",
    "\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "x_decoded_mean = Reshape([1,n_features])(x_decoded_mean)\n",
    "x_decoded_mean = UpSampling1D(size=100)(x_decoded_mean)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = n_features * metrics.mean_squared_error(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)\n",
    "    return xent_loss + 10*kl_loss\n",
    "\n",
    "vae = Model(x, x_decoded_mean)\n",
    "vae.compile(optimizer='adam', loss=vae_loss) # 'rmsprop'\n",
    "vae.summary()\n",
    "\n",
    "\n",
    "vae.fit(x=trainX_nominal, y=trainX_nominal, batch_size=656, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
