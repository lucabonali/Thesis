{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512000, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1024, 4)\n(11, 1024, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "beta = 1\n",
    "n_features = 4\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences_mix.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \"Acceleration\",\"Speed\"])\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "boat_val = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences_mix_val.csv\")\n",
    "boat_val = boat_val.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \"Acceleration\",\"Speed\"])\n",
    "scaler = StandardScaler()\n",
    "val_nom_data = scaler.fit_transform(boat_val)\n",
    "\n",
    "def prepare_sequences(data, batch_size):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0], batch_size):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "    sequences = np.array(samples)\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "    return trainX\n",
    "\n",
    "\n",
    "def prepare_data():    \n",
    "    trainX_nominal = prepare_sequences(normal_data,1024) \n",
    "    print(trainX_nominal.shape)\n",
    "    \n",
    "    valX_nominal = prepare_sequences(val_nom_data,1024)\n",
    "    print(valX_nominal.shape)\n",
    "\n",
    "    return trainX_nominal, valX_nominal\n",
    "\n",
    "trainX_nominal, valX_nominal = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 1024, 4)      0                                            \n__________________________________________________________________________________________________\nconv1d_91 (Conv1D)              (None, 1024, 64)     1856        encoder_input[0][0]              \n__________________________________________________________________________________________________\nmax_pooling1d_41 (MaxPooling1D) (None, 512, 64)      0           conv1d_91[0][0]                  \n__________________________________________________________________________________________________\nconv1d_92 (Conv1D)              (None, 512, 32)      14368       max_pooling1d_41[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_42 (MaxPooling1D) (None, 256, 32)      0           conv1d_92[0][0]                  \n__________________________________________________________________________________________________\nconv1d_93 (Conv1D)              (None, 256, 16)      3600        max_pooling1d_42[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_43 (MaxPooling1D) (None, 128, 16)      0           conv1d_93[0][0]                  \n__________________________________________________________________________________________________\nconv1d_94 (Conv1D)              (None, 128, 8)       904         max_pooling1d_43[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_44 (MaxPooling1D) (None, 64, 8)        0           conv1d_94[0][0]                  \n__________________________________________________________________________________________________\nflatten_11 (Flatten)            (None, 512)          0           max_pooling1d_44[0][0]           \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 6)            3078        flatten_11[0][0]                 \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 6)            3078        flatten_11[0][0]                 \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 6)            0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 26,884\nTrainable params: 26,884\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 6)                 0         \n_________________________________________________________________\nDense_after_sampling (Dense) (None, 512)               3584      \n_________________________________________________________________\nreshape_11 (Reshape)         (None, 64, 8)             0         \n_________________________________________________________________\nconv1d_95 (Conv1D)           (None, 64, 8)             456       \n_________________________________________________________________\nup_sampling1d_41 (UpSampling (None, 128, 8)            0         \n_________________________________________________________________\nconv1d_96 (Conv1D)           (None, 128, 16)           912       \n_________________________________________________________________\nup_sampling1d_42 (UpSampling (None, 256, 16)           0         \n_________________________________________________________________\nconv1d_97 (Conv1D)           (None, 256, 32)           3616      \n_________________________________________________________________\nup_sampling1d_43 (UpSampling (None, 512, 32)           0         \n_________________________________________________________________\nconv1d_98 (Conv1D)           (None, 512, 64)           14400     \n_________________________________________________________________\nup_sampling1d_44 (UpSampling (None, 1024, 64)          0         \n_________________________________________________________________\nconv1d_99 (Conv1D)           (None, 1024, 4)           1796      \n=================================================================\nTotal params: 24,764\nTrainable params: 24,764\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "input_shape = (1024, n_features)\n",
    "kernel_size = 3\n",
    "filters = 64\n",
    "latent_dim = 6\n",
    "use_mse = True\n",
    "load_weights = False\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for i in range(4):\n",
    "    x = Conv1D(filters=filters,\n",
    "               kernel_size=7,\n",
    "               padding='same')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    filters = int(filters / 2)\n",
    "\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2], name='Dense_after_sampling')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2]))(x)\n",
    "filters = filters * 2\n",
    "\n",
    "for i in range(4):\n",
    "    x = Conv1D(filters=filters,kernel_size=7, padding='same')(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    filters = filters * 2\n",
    "    \n",
    "    \n",
    "outputs = Conv1D(filters=n_features, kernel_size=7, padding='same')(x)\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "from keras.losses import mse\n",
    "\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n",
    "loss = reconstruction_loss + beta*kl_loss\n",
    "vae.add_loss(loss)\n",
    "\n",
    "vae.compile(optimizer='rmsprop', metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath=\"Models/Weights/weights.hdf5\", verbose=1,\n",
    "#                                save_best_only=True)\n",
    "# vae.fit(x=trainX_nominal, epochs=100, \n",
    "#         batch_size=1024,\n",
    "#         validation_data=(valX_nominal,None),\n",
    "#         callbacks=[checkpointer])\n",
    "vae.load_weights('Models/Weights/weights.hdf5')\n",
    "\n",
    "# vae.save(\"Models/Conv1d_VAE_comp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "orig_stdout = sys.stdout\n",
    "f = open('Logs/out.txt', 'w')\n",
    "sys.stdout = f\n",
    "print(encoder.summary())\n",
    "print(decoder.summary())\n",
    "sys.stdout = orig_stdout\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nom_autoenc = vae.predict(trainX_nominal)\n",
    "\n",
    "autoenc_df = pd.DataFrame(nom_autoenc[0], columns=boat_csv.columns)\n",
    "\n",
    "plt.plot(boat_csv['Lon'][:1024], boat_csv['Lat'][:1024])\n",
    "plt.show()\n",
    "plt.plot(autoenc_df['Lon'], autoenc_df['Lat'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 (500, 6)\n"
     ]
    }
   ],
   "source": [
    "nom_enc = encoder.predict(trainX_nominal)\n",
    "print(len(nom_enc), nom_enc[0].shape)\n",
    "\n",
    "def plot_enc_values():\n",
    "    neurons_m = []\n",
    "    neurons_var = []\n",
    "    for i in range(latent_dim):\n",
    "        neurons_m.append(nom_enc[0][:, i])\n",
    "        neurons_var.append(nom_enc[1][:, i])\n",
    "    \n",
    "    for i in range(latent_dim):\n",
    "        plt.plot(neurons_m[i])\n",
    "    plt.show()\n",
    "    \n",
    "    return neurons_m, neurons_var\n",
    "\n",
    "\n",
    "neurons_m, neurons_var = plot_enc_values()\n",
    "\n",
    "\n",
    "def check_disentanglement(neuron_index):\n",
    "    neuron_avg = np.average(neurons_m[neuron_index])\n",
    "    \n",
    "    neuron_var = np.average(neurons_var[neuron_index])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "VISUALIZATION\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "labels = np.array(pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")['label']) \n",
    "nominals = np.squeeze(np.argwhere(labels==1))\n",
    "anomalous = np.squeeze(np.argwhere(labels==0))\n",
    "print(type(nominals), type(nominals[0]))\n",
    "\n",
    "\n",
    "titles = [\"Mean\", \"Std\", \"Sampled\"]\n",
    "\n",
    "for i in nom_enc:\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(i)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    x_val = []\n",
    "    y_val=[]\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    \n",
    "    plt.scatter(x=x_val[nominals],y=y_val[nominals], alpha=0.5)\n",
    "    plt.scatter(x=x_val[anomalous],y=y_val[anomalous], alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne(data, title):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    \n",
    "    tsne_obj= tsne.fit_transform(data)\n",
    "    tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                            'Y':tsne_obj[:,1],\n",
    "                            })\n",
    "    \n",
    "    plt.scatter(x=tsne_df[\"X\"][nominals],\n",
    "                y=tsne_df[\"Y\"][nominals], alpha=0.5)\n",
    "    plt.scatter(x=tsne_df[\"X\"][anomalous],\n",
    "                y=tsne_df[\"Y\"][anomalous], alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return tsne_df\n",
    "\n",
    "for i in range(len(nom_enc)):\n",
    "    tsne_enc_nom_df = tsne(nom_enc[i], titles[i] )\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms\")\n",
    "dend_nom = shc.dendrogram(shc.linkage(tsne_enc_nom_df, method='ward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "cluster = AgglomerativeClustering(n_clusters=n_clusters, \n",
    "                                  affinity='euclidean',\n",
    "                                  linkage='ward')\n",
    "cl_nom = cluster.fit_predict(tsne_enc_nom_df)\n",
    "print(cl_nom)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_nom = []\n",
    "y_val_nom = []\n",
    "\n",
    "x_val_anom = []\n",
    "y_val_anom = []\n",
    "for i, xCoord in enumerate(tsne_enc_nom_df['X']):\n",
    "    if cl_nom[i] == 0:\n",
    "        x_val_nom.append(xCoord)\n",
    "        y_val_nom.append(tsne_enc_nom_df['Y'][i])\n",
    "    else:\n",
    "        x_val_anom.append(xCoord)\n",
    "        y_val_anom.append(tsne_enc_nom_df['Y'][i])\n",
    "\n",
    "plt.scatter(x=x_val_nom,\n",
    "            y=y_val_nom, alpha=0.5)\n",
    "plt.scatter(x=x_val_anom,\n",
    "            y=y_val_anom, alpha=0.5)\n",
    "plt.show()\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
