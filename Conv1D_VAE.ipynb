{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204800, 4)\n(200, 1024, 4)\n(10, 1024, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "n_features = 4\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences_mix.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \"Acceleration\",\"Speed\"])\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "boat_val = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequence_mix_val.csv\")\n",
    "boat_val = boat_val.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \"Acceleration\",\"Speed\"])\n",
    "scaler = StandardScaler()\n",
    "val_nom_data = scaler.fit_transform(boat_val)\n",
    "\n",
    "def prepare_sequences(data, batch_size):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0], batch_size):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "    sequences = np.array(samples)\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "    return trainX\n",
    "\n",
    "\n",
    "def prepare_data():    \n",
    "    trainX_nominal = prepare_sequences(normal_data,1024) \n",
    "    print(trainX_nominal.shape)\n",
    "    \n",
    "    valX_nominal = prepare_sequences(val_nom_data,1024)\n",
    "    print(valX_nominal.shape)\n",
    "\n",
    "    return trainX_nominal, valX_nominal\n",
    "\n",
    "trainX_nominal, valX_nominal = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 1024, 4)      0                                            \n__________________________________________________________________________________________________\nconv1d_19 (Conv1D)              (None, 1024, 64)     1856        encoder_input[0][0]              \n__________________________________________________________________________________________________\nmax_pooling1d_9 (MaxPooling1D)  (None, 512, 64)      0           conv1d_19[0][0]                  \n__________________________________________________________________________________________________\nconv1d_20 (Conv1D)              (None, 512, 32)      14368       max_pooling1d_9[0][0]            \n__________________________________________________________________________________________________\nmax_pooling1d_10 (MaxPooling1D) (None, 256, 32)      0           conv1d_20[0][0]                  \n__________________________________________________________________________________________________\nconv1d_21 (Conv1D)              (None, 256, 16)      3600        max_pooling1d_10[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_11 (MaxPooling1D) (None, 128, 16)      0           conv1d_21[0][0]                  \n__________________________________________________________________________________________________\nconv1d_22 (Conv1D)              (None, 128, 8)       904         max_pooling1d_11[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_12 (MaxPooling1D) (None, 64, 8)        0           conv1d_22[0][0]                  \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 512)          0           max_pooling1d_12[0][0]           \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 6)            3078        flatten_3[0][0]                  \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 6)            3078        flatten_3[0][0]                  \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 6)            0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 26,884\nTrainable params: 26,884\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 6)                 0         \n_________________________________________________________________\nDense_after_sampling (Dense) (None, 512)               3584      \n_________________________________________________________________\nreshape_3 (Reshape)          (None, 64, 8)             0         \n_________________________________________________________________\nconv1d_23 (Conv1D)           (None, 64, 8)             456       \n_________________________________________________________________\nup_sampling1d_9 (UpSampling1 (None, 128, 8)            0         \n_________________________________________________________________\nconv1d_24 (Conv1D)           (None, 128, 16)           912       \n_________________________________________________________________\nup_sampling1d_10 (UpSampling (None, 256, 16)           0         \n_________________________________________________________________\nconv1d_25 (Conv1D)           (None, 256, 32)           3616      \n_________________________________________________________________\nup_sampling1d_11 (UpSampling (None, 512, 32)           0         \n_________________________________________________________________\nconv1d_26 (Conv1D)           (None, 512, 64)           14400     \n_________________________________________________________________\nup_sampling1d_12 (UpSampling (None, 1024, 64)          0         \n_________________________________________________________________\nconv1d_27 (Conv1D)           (None, 1024, 4)           1796      \n=================================================================\nTotal params: 24,764\nTrainable params: 24,764\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import MaxPooling1D\n",
    "\n",
    "input_shape = (1024, n_features)\n",
    "kernel_size = 3\n",
    "filters = 64\n",
    "latent_dim = 6\n",
    "use_mse = True\n",
    "load_weights = False\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for i in range(4):\n",
    "    x = Conv1D(filters=filters,\n",
    "               kernel_size=7,\n",
    "               padding='same')(x)\n",
    "    x = MaxPooling1D(2)(x)\n",
    "    filters = int(filters / 2)\n",
    "\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2], name='Dense_after_sampling')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2]))(x)\n",
    "filters = filters * 2\n",
    "\n",
    "for i in range(4):\n",
    "    x = Conv1D(filters=filters,kernel_size=7, padding='same')(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    filters = filters * 2\n",
    "    \n",
    "    \n",
    "outputs = Conv1D(filters=n_features, kernel_size=7, padding='same')(x)\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "from keras.losses import mse\n",
    "\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n",
    "loss = reconstruction_loss + 1*kl_loss\n",
    "vae.add_loss(loss)\n",
    "\n",
    "vae.compile(optimizer='rmsprop', metrics= ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# checkpointer = ModelCheckpoint(filepath=\"Models/Weights/Nominal_weights.hdf5\", verbose=1,\n",
    "#                                save_best_only=True)\n",
    "# vae.fit(x=trainX_nominal, epochs=100, \n",
    "#         batch_size=1024,\n",
    "#         validation_data=(valX_nominal,None),\n",
    "#         callbacks=[checkpointer])\n",
    "vae.load_weights('Models/Weights/Nominal_weights.hdf5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "VISUALIZING RECONSTRUCTION ON FIRST RUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.23604478 -0.0450823   0.03794606 -0.01927547 -0.21131809  0.07257051]] [[-0.02129864 -0.00735012  0.02170739 -0.00085766 -0.05373051  0.09675059]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nom_autoenc = vae.predict(trainX_nominal)\n",
    "\n",
    "autoenc_df = pd.DataFrame(nom_autoenc[0], columns=boat_csv.columns)\n",
    "\n",
    "plt.plot(boat_csv['Lon'][:1024], boat_csv['Lat'][:1024])\n",
    "plt.show()\n",
    "plt.plot(autoenc_df['Lon'], autoenc_df['Lat'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ENCODED ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nom_enc = encoder.predict(trainX_nominal)\n",
    "print(len(nom_enc), nom_enc[0].shape)\n",
    "\n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "mat_mask = np.array([labels for i in range(latent_dim)])\n",
    "print(mat_mask.shape)\n",
    "\n",
    "def get_neuron_values():\n",
    "    neurons_m = []\n",
    "    neurons_var = []\n",
    "    for i in range(latent_dim):\n",
    "        neurons_m.append(nom_enc[0][:, i])\n",
    "        neurons_var.append(nom_enc[1][:, i])\n",
    "    \n",
    "    for i in range(latent_dim):\n",
    "        plt.plot(neurons_m[i])\n",
    "    plt.show()\n",
    "    \n",
    "    return neurons_m, neurons_var\n",
    "\n",
    "\n",
    "neurons_m, neurons_var = get_neuron_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nominal_parameters():\n",
    "    neuron_avg_nom = np.ma.array(neurons_m, mask=np.logical_not(mat_mask))\n",
    "    neuron_avg_nom = np.mean(neuron_avg_nom, axis=1)\n",
    "    neuron_var_nom = np.ma.array(neurons_var, mask=np.logical_not(mat_mask))\n",
    "    neuron_var_nom = np.mean(neuron_var_nom, axis=1)\n",
    "     \n",
    "    neuron_avg_anom = np.ma.array(neurons_m, mask=mat_mask)\n",
    "    neuron_avg_anom = np.mean(neuron_avg_anom, axis=1)\n",
    "    neuron_var_anom = np.ma.array(neurons_var, mask=mat_mask)\n",
    "    neuron_var_anom = np.mean(neuron_var_anom, axis=1)\n",
    "    \n",
    "    return neuron_avg_nom, neuron_var_nom, neuron_avg_anom, neuron_var_anom\n",
    "\n",
    "\n",
    "n_avg_nom, n_var_nom, n_avg_anom, n_var_anom = nominal_parameters()\n",
    "print(len(n_avg_nom), len(n_var_nom), len(n_avg_nom), len(n_var_anom))\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "DIFFERENCES IN ENCODING OF NOMINAL AND ANOMALOUS BEHAVIOUR VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_difference(avg_n, var_n, avg_an, var_an):\n",
    "    plt.plot(avg_n)\n",
    "    plt.plot(avg_an)\n",
    "    plt.title(\"MEAN\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(var_n)\n",
    "    plt.plot(var_an)\n",
    "    plt.title(\"STD\")\n",
    "    plt.show()\n",
    "\n",
    "visualize_difference(n_avg_nom, n_var_nom, n_avg_anom, n_var_anom)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ANALYSIS OF ENCODING AND DECODING OF THE ANOMALOUS RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08811088  0.1255463   0.01701382 -0.08566583  0.1815099  -0.00088965] [ 0.16391774  0.00667964 -0.08026419 -0.01931977 -0.09087465  0.04685581]\n"
     ]
    }
   ],
   "source": [
    "boat_anom_csv = pd.read_csv(\"Data/Boat_anom_sequence.csv\")\n",
    "boat_anom_csv = boat_anom_csv.drop(columns=[\"Unnamed: 0\",\"Speed\", \"Acceleration\",\n",
    "                                            \"M0C\", \"M1C\"])\n",
    "anom_data_norm = scaler.fit_transform(boat_anom_csv)\n",
    "anom_data_norm = np.reshape(anom_data_norm, (1, len(anom_data_norm), n_features))\n",
    "anom_data_encoding = np.squeeze(encoder.predict(anom_data_norm))\n",
    "\n",
    "anom_means = anom_data_encoding[0]\n",
    "anom_var = anom_data_encoding[1]\n",
    "print(anom_means, anom_var)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "SAMPLING FROM VALUES OF THE LATENT SPACE AND CHANGING ONLY ONE, \n",
    "THEN CHECK THE RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_sampled(sample_nom, sample_anom):\n",
    "    plt.plot(sample_nom)    \n",
    "    plt.plot(sample_anom)\n",
    "    plt.title(\"SAMPLED DIFFERENCES\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def reconstruct_from_latent_vectors(latents):\n",
    "    latents = np.reshape(latents, (1,len(latents)))\n",
    "    run = decoder.predict(latents)\n",
    "    run_df = pd.DataFrame(run[0], columns=boat_csv.columns)\n",
    "    \n",
    "    plt.plot(run_df[\"Sin\"])\n",
    "    plt.plot(run_df[\"Lat\"])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "epsilon = np.random.normal(0,1)\n",
    "sample_nominal = neuron_avg + np.exp(0.5*neuron_var)*epsilon\n",
    "sample_anomalous = anom_means + np.exp(0.5*anom_var)*epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = np.linspace(0,10,50)\n",
    "neur = 5\n",
    "for i in changes:\n",
    "    sample_nominal[neur] = sample_anomalous[neur]*i\n",
    "    #visualize_latent_sampled(sample_nominal, sample_anomalous)\n",
    "    reconstruct_from_latent_vectors(sample_nominal)\n",
    "# reconstruct_from_latent_vectors(sample_anomalous)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "VISUALIZATION of ENCODED VALUES OF MEAN AND SIGMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "labels = np.array(pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")['label']) \n",
    "nominals = np.squeeze(np.argwhere(labels==1))\n",
    "anomalous = np.squeeze(np.argwhere(labels==0))\n",
    "print(type(nominals), type(nominals[0]))\n",
    "\n",
    "\n",
    "titles = [\"Mean\", \"Std\", \"Sampled\"]\n",
    "\n",
    "for i in nom_enc:\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(i)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    x_val = []\n",
    "    y_val=[]\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    \n",
    "    plt.scatter(x=x_val[nominals],y=y_val[nominals], alpha=0.5)\n",
    "    plt.scatter(x=x_val[anomalous],y=y_val[anomalous], alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne(data, title):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    \n",
    "    tsne_obj= tsne.fit_transform(data)\n",
    "    tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                            'Y':tsne_obj[:,1],\n",
    "                            })\n",
    "    \n",
    "    plt.scatter(x=tsne_df[\"X\"][nominals],\n",
    "                y=tsne_df[\"Y\"][nominals], alpha=0.5)\n",
    "    plt.scatter(x=tsne_df[\"X\"][anomalous],\n",
    "                y=tsne_df[\"Y\"][anomalous], alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return tsne_df\n",
    "\n",
    "for i in range(len(nom_enc)):\n",
    "    tsne_enc_nom_df = tsne(nom_enc[i], titles[i] )\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms\")\n",
    "dend_nom = shc.dendrogram(shc.linkage(tsne_enc_nom_df, method='ward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "cluster = AgglomerativeClustering(n_clusters=n_clusters, \n",
    "                                  affinity='euclidean',\n",
    "                                  linkage='ward')\n",
    "cl_nom = cluster.fit_predict(tsne_enc_nom_df)\n",
    "print(cl_nom)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_nom = []\n",
    "y_val_nom = []\n",
    "\n",
    "x_val_anom = []\n",
    "y_val_anom = []\n",
    "for i, xCoord in enumerate(tsne_enc_nom_df['X']):\n",
    "    if cl_nom[i] == 0:\n",
    "        x_val_nom.append(xCoord)\n",
    "        y_val_nom.append(tsne_enc_nom_df['Y'][i])\n",
    "    else:\n",
    "        x_val_anom.append(xCoord)\n",
    "        y_val_anom.append(tsne_enc_nom_df['Y'][i])\n",
    "\n",
    "plt.scatter(x=x_val_nom,\n",
    "            y=y_val_nom, alpha=0.5)\n",
    "plt.scatter(x=x_val_anom,\n",
    "            y=y_val_anom, alpha=0.5)\n",
    "plt.show()\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
