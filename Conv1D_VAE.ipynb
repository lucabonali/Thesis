{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307200, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1024, 4)\n(30, 1024, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "n_features = 4\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences_mix.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "boat_val = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequence_mix_val.csv\")\n",
    "boat_val = boat_val.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "val_nom_data = scaler.fit_transform(boat_val)\n",
    "\n",
    "def prepare_sequences(data, batch_size):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0], batch_size):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "    sequences = np.array(samples)\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "    return trainX\n",
    "\n",
    "\n",
    "def prepare_data():    \n",
    "    trainX_nominal = prepare_sequences(normal_data,1024) \n",
    "    print(trainX_nominal.shape)\n",
    "    \n",
    "    valX_nominal = prepare_sequences(val_nom_data,1024)\n",
    "    print(valX_nominal.shape)\n",
    "\n",
    "    return trainX_nominal, valX_nominal\n",
    "\n",
    "trainX_nominal, valX_nominal = prepare_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\nCreating VAE with beta= 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 1024, 4)      0                                            \n__________________________________________________________________________________________________\ndense_123 (Dense)               (None, 1024, 30)     150         encoder_input[0][0]              \n__________________________________________________________________________________________________\ndense_124 (Dense)               (None, 1024, 30)     930         dense_123[0][0]                  \n__________________________________________________________________________________________________\ndense_125 (Dense)               (None, 1024, 30)     930         dense_124[0][0]                  \n__________________________________________________________________________________________________\ndense_126 (Dense)               (None, 1024, 30)     930         dense_125[0][0]                  \n__________________________________________________________________________________________________\ndense_127 (Dense)               (None, 1024, 30)     930         dense_126[0][0]                  \n__________________________________________________________________________________________________\nflatten_17 (Flatten)            (None, 30720)        0           dense_127[0][0]                  \n__________________________________________________________________________________________________\ndense_128 (Dense)               (None, 30)           921630      flatten_17[0][0]                 \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 20)           620         dense_128[0][0]                  \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 20)           620         dense_128[0][0]                  \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 20)           0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 926,740\nTrainable params: 926,740\nNon-trainable params: 0\n__________________________________________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 20)                0         \n_________________________________________________________________\nDense_after_sampling (Dense) (None, 30)                630       \n_________________________________________________________________\ndense_129 (Dense)            (None, 30)                930       \n_________________________________________________________________\ndense_130 (Dense)            (None, 30)                930       \n_________________________________________________________________\ndense_131 (Dense)            (None, 30)                930       \n_________________________________________________________________\ndense_132 (Dense)            (None, 30)                930       \n_________________________________________________________________\nrepeat_vector_11 (RepeatVect (None, 1024, 30)          0         \n_________________________________________________________________\ndense_133 (Dense)            (None, 1024, 4)           124       \n=================================================================\nTotal params: 4,474\nTrainable params: 4,474\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import MaxPooling1D, MaxPool1D, Conv2DTranspose, BatchNormalization, RepeatVector\n",
    "import tensorflow as tf\n",
    "\n",
    "input_shape = (None, n_features)\n",
    "latent_dim = 20\n",
    "kernel_size = 2\n",
    "use_mse = True   \n",
    "load_weights = False\n",
    "random_weight = 1\n",
    "\n",
    "\n",
    "def create_vae(beta):\n",
    "    filters = 16\n",
    "    units = len(trainX_nominal)\n",
    "    units = 30\n",
    "\n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # by default, random_normal has mean=0 and std=1.0\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    \n",
    "    def Conv1DTranspose(input_tensor, filters, kernel_size,last, strides=2, padding='same'):\n",
    "        if last:\n",
    "            activation = 'linear'\n",
    "        else:\n",
    "            activation = 'relu'\n",
    "        x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), \n",
    "                            strides=(strides, 1), padding=padding,\n",
    "                            activation=activation)(x)\n",
    "        x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    inputs = Input(shape=input_shape, name='encoder_input')\n",
    "    x = inputs\n",
    "    for i in range(5):\n",
    "        #filters *= 2\n",
    "        # x = Conv1D(filters=filters,\n",
    "        #            kernel_size=kernel_size,\n",
    "        #            padding='same',\n",
    "        #            activation='relu',\n",
    "        #            strides=2)(x)\n",
    "        x = Dense(units=units, activation='relu')(x)\n",
    "    #shape = K.int_shape(x)\n",
    "\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(30, activation='relu')(x) \n",
    "    #x = BatchNormalization(momentum=0.0)(x)\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "    #z_mean = BatchNormalization(momentum=0.0)(z_mean)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "    #z_log_var = BatchNormalization(momentum=0.0)(z_log_var)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    encoder.summary()\n",
    "\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(units=units, name='Dense_after_sampling', activation='relu')(latent_inputs)\n",
    "\n",
    "    filters = 50\n",
    "    for i in range(4):\n",
    "        # x = Conv1DTranspose(input_tensor=x,\n",
    "        #                     filters=filters, \n",
    "        #                     kernel_size=kernel_size, \n",
    "        #                     padding='same',\n",
    "        #                     last=False)\n",
    "        #filters //= 2\n",
    "        #x = UpSampling1D(size=2)(x)\n",
    "        x = Dense(units=units, activation='relu')(x)\n",
    "\n",
    "    \n",
    "    # outputs = Conv1DTranspose(input_tensor=x,\n",
    "    #                           filters=n_features, \n",
    "    #                           kernel_size=2, padding='same',\n",
    "    #                           last=True)\n",
    "    outputs = RepeatVector(1024)(x)\n",
    "    outputs = Dense(n_features)(outputs)\n",
    "\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    decoder.summary()\n",
    "\n",
    "    outputs = decoder(encoder(inputs)[2])\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "    from keras.losses import mse\n",
    "\n",
    "    reconstruction_loss = 1024*mse(K.flatten(inputs), K.flatten(outputs))\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1)\n",
    "    kl_loss *= -0.5\n",
    "    loss = K.mean(reconstruction_loss)\n",
    "    \n",
    "    vae.add_loss(loss)\n",
    "\n",
    "    vae.compile(optimizer='rmsprop')\n",
    "\n",
    "    return (vae, encoder, decoder)\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "betas = np.linspace(1,1,1)\n",
    "print(betas)\n",
    "\n",
    "\n",
    "vaes = []\n",
    "for i, beta in enumerate(betas):\n",
    "    print(\"Creating VAE with beta=\", betas[i])\n",
    "    vaes.append(create_vae(beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FITTING Vae with beta = 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/300 [==>...........................] - ETA: 30s - loss: 1053.8440"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 13s - loss: 1102.5256"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 8s - loss: 1094.5135 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 5s - loss: 1078.0210"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/300 [===============>..............] - ETA: 3s - loss: 1069.2644"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r192/300 [==================>...........] - ETA: 2s - loss: 1062.1263"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/300 [=====================>........] - ETA: 1s - loss: 1058.4496"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r256/300 [========================>.....] - ETA: 0s - loss: 1054.3523"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r288/300 [===========================>..] - ETA: 0s - loss: 1051.1111"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 4s 15ms/step - loss: 1050.2252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n\r 32/300 [==>...........................] - ETA: 0s - loss: 1029.8721"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1028.9537"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 0s - loss: 1027.7566"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1027.6143"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/300 [===============>..............] - ETA: 0s - loss: 1027.2787"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1026.5310"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/300 [=====================>........] - ETA: 0s - loss: 1025.8895"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1025.5348"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r288/300 [===========================>..] - ETA: 0s - loss: 1026.2132"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 1s 3ms/step - loss: 1026.4677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/300 [==>...........................] - ETA: 1s - loss: 1025.2439"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1026.2917"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 0s - loss: 1025.2313"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1023.9037"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/300 [===============>..............] - ETA: 0s - loss: 1025.1437"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1024.8281"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/300 [=====================>........] - ETA: 0s - loss: 1024.6270"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1025.0250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r288/300 [===========================>..] - ETA: 0s - loss: 1025.0956"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 1s 3ms/step - loss: 1025.2991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/300 [==>...........................] - ETA: 0s - loss: 1021.6741"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1026.7023"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 0s - loss: 1026.2914"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1027.0106"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1025.9674"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1024.9002"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 2ms/step - loss: 1024.6223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n\r 32/300 [==>...........................] - ETA: 0s - loss: 1021.6469"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1021.2599"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 0s - loss: 1022.3400"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1021.9307"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1022.2550"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1024.2820"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 2ms/step - loss: 1024.1592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n\r 32/300 [==>...........................] - ETA: 0s - loss: 1024.4136"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1024.5015"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1024.9382"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1023.7825"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1024.2631"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 1ms/step - loss: 1024.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 32/300 [==>...........................] - ETA: 0s - loss: 1024.7161"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1026.3939"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1029.4496"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1026.3831"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1025.5790"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 1ms/step - loss: 1026.3080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/300 [==>...........................] - ETA: 0s - loss: 1024.9285"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1026.8444"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 0s - loss: 1028.6237"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1025.8429"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1024.0318"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1023.4980"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 2ms/step - loss: 1023.3388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n\r 32/300 [==>...........................] - ETA: 0s - loss: 1017.4937"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 0s - loss: 1021.8929"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/300 [===============>..............] - ETA: 0s - loss: 1024.0612"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/300 [=====================>........] - ETA: 0s - loss: 1023.5656"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r288/300 [===========================>..] - ETA: 0s - loss: 1023.1661"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 1ms/step - loss: 1023.1132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n\r 32/300 [==>...........................] - ETA: 0s - loss: 1025.1240"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 0s - loss: 1021.2458"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 0s - loss: 1023.4152"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 0s - loss: 1022.4033"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 0s - loss: 1025.7526"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1024.6094"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 0s 2ms/step - loss: 1024.1426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(vaes)):\n",
    "    # checkpointer = ModelCheckpoint(filepath=\"Models/Weights/Nominal_weights_vae.hdf5\",\n",
    "    #                                verbose=1, save_best_only=True)\n",
    "    print(\"FITTING Vae with beta =\", betas[i])\n",
    "    vaes[i][0].fit(x=trainX_nominal,\n",
    "            epochs=10)#batch_size=1024)\n",
    "    #vaes[i][0].load_weights('Models/Weights/Nominal_weights_vae.hdf5')\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ENCODED ANALYSIS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mask(num, labels):\n",
    "    return np.squeeze(np.argwhere(labels == num))\n",
    "\n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "masks = [return_mask(num,labels)[:,0] for num in range(0,9)]\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "model_index = 0\n",
    "encodings = []\n",
    "\n",
    "for i in vaes:\n",
    "    encodings.append(i[1].predict(trainX_nominal))\n",
    "\n",
    "#encodings = [encoder.predict(trainX_nominal)]\n",
    "\n",
    "def check_z_sampling(encoded_values):\n",
    "    m = encoded_values[0]\n",
    "    var = np.exp(0.5*encoded_values[1])\n",
    "    eps = np.random.normal(0,1,latent_dim)\n",
    "    \n",
    "    sampled = []\n",
    "    index = 0\n",
    "    var_zero = np.zeros(10)\n",
    "    for means in m:\n",
    "        sample = means+var[index]*eps\n",
    "        #sample = means+var_zero*eps \n",
    "        sampled.append(sample)\n",
    "        index += 1\n",
    "    \n",
    "    sampled = np.array(sampled)\n",
    "    return sampled\n",
    "\n",
    "def plot_pca(title, type): \n",
    "    x_val = []\n",
    "    y_val= []\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    for mask in masks:\n",
    "        plt.scatter(x=x_val[mask], y=y_val[mask], alpha=0.5)\n",
    "\n",
    "    plt.legend(labels=np.arange(0,9))\n",
    "    plt.title(str(title)+\"\"+type)\n",
    "    plt.show()\n",
    "    \n",
    "titles=['z_mean','z_log_var','z']\n",
    "for i, encod in enumerate(encodings):\n",
    "        for j in range(3):\n",
    "            latent_values = check_z_sampling(encod)\n",
    "            scaler = StandardScaler()\n",
    "            enc_input = scaler.fit_transform(encod[j]) \n",
    "            pca = PCA(2)\n",
    "            principalComponents = pca.fit_transform(enc_input)\n",
    "            #print(pca.explained_variance_ratio_)\n",
    "            plot_pca(betas[i], titles[j])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "UNSEEN DATA PLOTTING IN PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "boat_strange = pd.read_csv(\"Data/Boat_nominal_data/Boat_unseen.csv\")\n",
    "boat_strange = boat_strange.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = MinMaxScaler()\n",
    "boat_unseen_data = scaler.fit_transform(boat_strange)\n",
    "#boat_unseen_data = np.array(boat_strange)\n",
    "boat_unseen_data = np.reshape(boat_unseen_data, (1,len(boat_unseen_data),n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.7921036, -3.8114154]], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_encoding = vaes[0][1].predict(boat_unseen_data)\n",
    "pca.transform(unseen_encoding[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "CLUSTERING OF LATENT SPACE and Reconstruction Analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(192, 1024, 4)\n(15, 1024, 4)\n(11, 1024, 4)\n(12, 1024, 4)\n(14, 1024, 4)\n(11, 1024, 4)\n(13, 1024, 4)\n(16, 1024, 4)\n(16, 1024, 4)\n"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "for mask in masks:\n",
    "    run_for_class = trainX_nominal[mask]\n",
    "    print(run_for_class.shape)\n",
    "    runs.append(run_for_class)\n",
    "    \n",
    "for i in runs[0]:\n",
    "    run = np.reshape(i, (1, 1024,4))\n",
    "    rec = vaes[0][0].predict(run)\n",
    "    rec = np.reshape(rec, (len(trainX_nominal[0]), n_features))\n",
    "    reconstruction_df = pd.DataFrame(rec, columns=boat_csv.columns)\n",
    "    \n",
    "    plt.plot(reconstruction_df[\"Lon\"], reconstruction_df[\"Lat\"])\n",
    "    #plt.savefig(\"Imgs/Latent_reconstruction/\"+str(title)+\".png\")\n",
    "    plt.show()\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "PCA and TSNE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encodings = []\n",
    "\n",
    "for i in vaes:\n",
    "    encodings.append(i[1].predict(trainX_nominal))\n",
    "\n",
    "def check_z_sampling(encoded_values):\n",
    "    m = encoded_values[0]\n",
    "    var = np.exp(0.5*encoded_values[1])\n",
    "    eps = np.random.normal(0,1,latent_dim)\n",
    "    \n",
    "    sampled = []\n",
    "    index = 0\n",
    "    var_zero = np.zeros(10)\n",
    "    for means in m:\n",
    "        sample = means+var[index]*eps\n",
    "        #sample = means+var_zero*eps \n",
    "        \n",
    "        sampled.append(sample)\n",
    "        index +=1\n",
    "    \n",
    "    sampled = np.array(sampled)\n",
    "    return sampled\n",
    "    \n",
    "values = check_z_sampling(encodings[0])\n",
    "\n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "mat_mask = np.array([labels for i in range(latent_dim)])\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "labels = np.array(pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")['label']) \n",
    "nominals = np.squeeze(np.argwhere(labels==1))\n",
    "anomalous = np.squeeze(np.argwhere(labels==0))\n",
    "print(type(nominals), type(nominals[0]))\n",
    "\n",
    "model_index = 0\n",
    "\n",
    "titles = [\"Mean\", \"Std\", \"Sampled\"]\n",
    "\n",
    "for i in encodings[model_index]:\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(i)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    x_val = []\n",
    "    y_val=[]\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    \n",
    "    plt.scatter(x=x_val[nominals],y=y_val[nominals], alpha=0.5)\n",
    "    plt.scatter(x=x_val[anomalous],y=y_val[anomalous], alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne(data, title):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    \n",
    "    tsne_obj= tsne.fit_transform(data)\n",
    "    tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                            'Y':tsne_obj[:,1],\n",
    "                            })\n",
    "    \n",
    "    plt.scatter(x=tsne_df[\"X\"][nominals],\n",
    "                y=tsne_df[\"Y\"][nominals], alpha=0.5)\n",
    "    plt.scatter(x=tsne_df[\"X\"][anomalous],\n",
    "                y=tsne_df[\"Y\"][anomalous], alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return tsne_df\n",
    "\n",
    "for i, encode in enumerate(encodings[model_index]):\n",
    "    tsne_enc_nom_df = tsne(encode, titles[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sample_from_latent_space(xCoord, yCoord):\n",
    "    point = np.array([xCoord,yCoord])\n",
    "    latent_point = pca.inverse_transform(point)\n",
    "    return np.reshape(latent_point,(1, latent_dim))\n",
    "\n",
    "def visualize_reconstruction(reconstructed_run, title):\n",
    "    plt.plot(reconstructed_run[\"Lon\"], reconstructed_run[\"Lat\"])\n",
    "    plt.title(title)\n",
    "    \n",
    "    # plt.plot(reconstructed_run[\"Sin\"])\n",
    "    # plt.plot(reconstructed_run[\"Cosin\"])\n",
    "    # plt.title(title)\n",
    "    plt.savefig(\"Imgs/Latent_analysis/\"+str(title)+\".png\")\n",
    "    plt.clf()\n",
    "    # plt.show()\n",
    "\n",
    "X,Y = np.mgrid[-5:5:0.5, -5:5:0.5]\n",
    "XY = np.vstack((X.flatten(), Y.flatten())).T\n",
    "print(XY.shape)\n",
    "\n",
    "for i,p in enumerate(XY):    \n",
    "    point = sample_from_latent_space(p[0],p[1])\n",
    "    reconstructed = np.reshape(vaes[model_index][2].predict(point), (len(trainX_nominal[0]),n_features))\n",
    "    visualize_reconstruction(pd.DataFrame(reconstructed, columns=boat_csv.columns), \n",
    "                             title=str(i)+str(p))\n",
    "\n",
    "# line = np.arange(-10, 10, 0.5)\n",
    "# \n",
    "# for i,point2d in enumerate(line):\n",
    "#     point = sample_from_latent_space(point2d,point2d)\n",
    "#     reconstructed = np.reshape(vaes[model_index][2].predict(point), (len(trainX_nominal[0]),n_features))\n",
    "#     visualize_reconstruction(pd.DataFrame(reconstructed, columns=boat_csv.columns), \n",
    "#                              title=point2d)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "OLD STUFF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 500, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_neuron_values(encoding):\n",
    "    neurons_m = []\n",
    "    neurons_var = []\n",
    "    for i in range(latent_dim):\n",
    "        neurons_m.append(encoding[0][:, i])\n",
    "        neurons_var.append(encoding[1][:, i])\n",
    "    \n",
    "    for i in range(latent_dim):\n",
    "        plt.plot(neurons_m[i])\n",
    "    plt.show()\n",
    "    \n",
    "    return (neurons_m, neurons_var)\n",
    "\n",
    "neuron_values = []\n",
    "for i in encodings:\n",
    " neuron_values.append(get_neuron_values(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def nominal_parameters(n_m, n_var):\n",
    "    neuron_avg_nom = np.ma.array(n_m, mask=np.logical_not(mat_mask))\n",
    "    neuron_avg_nom = np.mean(neuron_avg_nom, axis=1)\n",
    "    neuron_var_nom = np.ma.array(n_var, mask=np.logical_not(mat_mask))\n",
    "    neuron_var_nom = np.mean(neuron_var_nom, axis=1)\n",
    "     \n",
    "    neuron_avg_anom = np.ma.array(n_m, mask=mat_mask)\n",
    "    neuron_avg_anom = np.mean(neuron_avg_anom, axis=1)\n",
    "    neuron_var_anom = np.ma.array(n_var, mask=mat_mask)\n",
    "    neuron_var_anom = np.mean(neuron_var_anom, axis=1)\n",
    "    \n",
    "    return (neuron_avg_nom, neuron_var_nom, neuron_avg_anom, neuron_var_anom)\n",
    "\n",
    "enc_values = []\n",
    "for i in neuron_values:\n",
    "    enc_values.append(nominal_parameters(i[0], i[1]))\n",
    "print(len(enc_values))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "DIFFERENCES IN ENCODING OF NOMINAL AND ANOMALOUS BEHAVIOUR VISUALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_difference(avg_n, var_n, avg_an, var_an):\n",
    "    plt.plot(avg_n)\n",
    "    plt.plot(avg_an)\n",
    "    plt.title(\"MEAN\")\n",
    "    plt.show()\n",
    "    \n",
    "    # plt.plot(var_n)\n",
    "    # plt.plot(var_an)\n",
    "    # plt.title(\"STD\")\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "for i in enc_values:\n",
    "    visualize_difference(i[0], i[1], i[2], i[3])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ANALYSIS OF ENCODING AND DECODING OF THE ANOMALOUS RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08811088  0.1255463   0.01701382 -0.08566583  0.1815099  -0.00088965] [ 0.16391774  0.00667964 -0.08026419 -0.01931977 -0.09087465  0.04685581]\n"
     ]
    }
   ],
   "source": [
    "boat_anom_csv = pd.read_csv(\"Data/Boat_anom_sequence.csv\")\n",
    "boat_anom_csv = boat_anom_csv.drop(columns=[\"Unnamed: 0\",\"Speed\", \"Acceleration\",\n",
    "                                            \"M0C\", \"M1C\"])\n",
    "anom_data_norm = scaler.fit_transform(boat_anom_csv)\n",
    "anom_data_norm = np.reshape(anom_data_norm, (1, len(anom_data_norm), n_features))\n",
    "anom_data_encoding = np.squeeze(encoder.predict(anom_data_norm))\n",
    "\n",
    "anom_means = anom_data_encoding[0]\n",
    "anom_var = anom_data_encoding[1]\n",
    "print(anom_means, anom_var)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "SAMPLING FROM VALUES OF THE LATENT SPACE AND CHANGING ONLY ONE, \n",
    "THEN CHECK THE RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_sampled(sample_nom, sample_anom):\n",
    "    plt.plot(sample_nom)    \n",
    "    plt.plot(sample_anom)\n",
    "    plt.title(\"SAMPLED DIFFERENCES\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def reconstruct_from_latent_vectors(latents, model_index):\n",
    "    latents = np.reshape(latents, (1,len(latents)))\n",
    "    run = vaes[model_index][2].predict(latents)\n",
    "    run_df = pd.DataFrame(run[0], columns=boat_csv.columns)\n",
    "    \n",
    "    plt.plot(run_df[\"Lon\"])#, run_df[\"Lat\"])\n",
    "    plt.plot(run_df[\"Lat\"])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "epsilon = np.random.normal(0,1)\n",
    "sample_nominal = enc_values[0][0] + np.exp(0.5*enc_values[0][1])*epsilon\n",
    "sample_anomalous = enc_values[0][2] + np.exp(0.5*enc_values[0][3])*epsilon\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes = np.linspace(0,6,50)\n",
    "neur = 0\n",
    "for i in changes:\n",
    "    sample_nominal[neur] = sample_anomalous[neur]*i\n",
    "    #visualize_latent_sampled(sample_nominal, sample_anomalous)\n",
    "    reconstruct_from_latent_vectors(sample_nominal,0)\n",
    "# reconstruct_from_latent_vectors(sample_anomalous)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "VISUALIZATION of ENCODED VALUES OF MEAN AND SIGMA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "labels = np.array(pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")['label']) \n",
    "nominals = np.squeeze(np.argwhere(labels==1))\n",
    "anomalous = np.squeeze(np.argwhere(labels==0))\n",
    "print(type(nominals), type(nominals[0]))\n",
    "\n",
    "model_index = 0\n",
    "\n",
    "titles = [\"Mean\", \"Std\", \"Sampled\"]\n",
    "\n",
    "for i in encodings[model_index]:\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(i)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    x_val = []\n",
    "    y_val=[]\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    x_val = np.array(x_val)\n",
    "    y_val = np.array(y_val)\n",
    "    \n",
    "    \n",
    "    plt.scatter(x=x_val[nominals],y=y_val[nominals], alpha=0.5)\n",
    "    plt.scatter(x=x_val[anomalous],y=y_val[anomalous], alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def tsne(data, title):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    \n",
    "    tsne_obj= tsne.fit_transform(data)\n",
    "    tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                            'Y':tsne_obj[:,1],\n",
    "                            })\n",
    "    \n",
    "    plt.scatter(x=tsne_df[\"X\"][nominals],\n",
    "                y=tsne_df[\"Y\"][nominals], alpha=0.5)\n",
    "    plt.scatter(x=tsne_df[\"X\"][anomalous],\n",
    "                y=tsne_df[\"Y\"][anomalous], alpha=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "    return tsne_df\n",
    "\n",
    "for i, encode in enumerate(encodings[model_index]):\n",
    "    tsne_enc_nom_df = tsne(encode, titles[i])\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "ANALYZING SPACE OF PCA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 2)\n"
     ]
    }
   ],
   "source": [
    "def sample_from_latent_space(xCoord, yCoord):\n",
    "    point = np.array([xCoord,yCoord])\n",
    "    latent_point = pca.inverse_transform(point)\n",
    "    return np.reshape(latent_point,(1, latent_dim))\n",
    "\n",
    "def visualize_reconstruction(reconstructed_run, title):\n",
    "    plt.plot(reconstructed_run[\"Lon\"], reconstructed_run[\"Lat\"])\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    # plt.plot(reconstructed_run[\"Sin\"])\n",
    "    # plt.plot(reconstructed_run[\"Cosin\"])\n",
    "    # plt.show()\n",
    "\n",
    "line = np.arange(-6, 6, 0.5)\n",
    "X,Y = np.mgrid[-4:4:0.5, -4:4:0.5]\n",
    "XY = np.vstack((X.flatten(), Y.flatten())).T\n",
    "print(XY.shape)\n",
    "\n",
    "for p in XY:    \n",
    "    point = sample_from_latent_space(p[1],p[0])\n",
    "    reconstructed = np.reshape(vaes[model_index][2].predict(point), (len(trainX_nominal[0]),n_features))\n",
    "    visualize_reconstruction(pd.DataFrame(reconstructed, columns=boat_csv.columns), \n",
    "                             title=p)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Customer Dendograms\")\n",
    "dend_nom = shc.dendrogram(shc.linkage(tsne_enc_nom_df, method='ward'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "cluster = AgglomerativeClustering(n_clusters=n_clusters, \n",
    "                                  affinity='euclidean',\n",
    "                                  linkage='ward')\n",
    "cl_nom = cluster.fit_predict(tsne_enc_nom_df)\n",
    "print(cl_nom)\n",
    "\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_nom = []\n",
    "y_val_nom = []\n",
    "\n",
    "x_val_anom = []\n",
    "y_val_anom = []\n",
    "for i, xCoord in enumerate(tsne_enc_nom_df['X']):\n",
    "    if cl_nom[i] == 0:\n",
    "        x_val_nom.append(xCoord)\n",
    "        y_val_nom.append(tsne_enc_nom_df['Y'][i])\n",
    "    else:\n",
    "        x_val_anom.append(xCoord)\n",
    "        y_val_anom.append(tsne_enc_nom_df['Y'][i])\n",
    "\n",
    "plt.scatter(x=x_val_nom,\n",
    "            y=y_val_nom, alpha=0.5)\n",
    "plt.scatter(x=x_val_anom,\n",
    "            y=y_val_anom, alpha=0.5)\n",
    "plt.show()\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
