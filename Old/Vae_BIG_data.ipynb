{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66963, 7)\n(6620, 7)\n(100, 663, 7)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras import Model\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "import keras as kr\n",
    "import keras.losses as losses\n",
    "\n",
    "intermediate_dim = 300\n",
    "latent_dim = 7\n",
    "beta = 5\n",
    "epochs = 15\n",
    "n_sequences = 101\n",
    "n_features = 7\n",
    "sequence_lenght = 663\n",
    "\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "# boat_csv = boat_csv[:5739]\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "boat_curved = pd.read_csv(\"Data/Anomalous_boat_data.csv\")\n",
    "boat_curved= boat_curved.drop(columns=[\"Unnamed: 0\", \"heading\"])    \n",
    "scaler = StandardScaler()\n",
    "anomalous_data = scaler.fit_transform(boat_curved)\n",
    "print(anomalous_data.shape)\n",
    "\n",
    "batch_size =  663\n",
    "interval = 663\n",
    "def prepare_sequences(data):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0]- batch_size, interval):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "\n",
    "    sequences = np.array(samples)\n",
    "\n",
    "    # Batch size (Number of samples time steps and number of features\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, 7))\n",
    "\n",
    "    return trainX\n",
    "\n",
    "trainX_nominal = prepare_sequences(normal_data) \n",
    "print(trainX_nominal.shape)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 7 and 663 for 'z_5/mul_1' (op: 'Mul') with input shapes: [?,663,7], [?,663].",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1863\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1864\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1865\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 7 and 663 for 'z_5/mul_1' (op: 'Mul') with input shapes: [?,663,7], [?,663].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ab67c7fd91ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-ab67c7fd91ee>\u001b[0m in \u001b[0;36mcreate_vae\u001b[1;34m(beta)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# use reparameterization trick to push the sampling out as input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# note that \"output_shape\" isn't necessary with the TensorFlow backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'z'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# Instantiate the encoder model:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m             \u001b[1;31m# Actually call the layer,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m    685\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mask'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[0marguments\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-ab67c7fd91ee>\u001b[0m in \u001b[0;36msampling\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# by default, random_normal has mean = 0 and std = 1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mz_mean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mz_log_var\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m# use reparameterization trick to push the sampling out as input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 884\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    885\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1178\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6487\u001b[0m   \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6488\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 6489\u001b[1;33m         \"Mul\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   6490\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6491\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[0;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    789\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m                 instructions)\n\u001b[1;32m--> 507\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3616\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3618\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 2027\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   2028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2029\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1865\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 7 and 663 for 'z_5/mul_1' (op: 'Mul') with input shapes: [?,663,7], [?,663]."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "def create_vae(beta):\n",
    "\n",
    "    # Map inputs to the latent distribution parameters:\n",
    "    # VAE model = encoder + decoder\n",
    "    # build encoder model\n",
    "    inputs = Input(shape=(sequence_lenght, 7), name='encoder_input')\n",
    "    conv1 = Conv1D(filters=200, \n",
    "                   padding='same', \n",
    "                   kernel_size=n_features)(inputs)\n",
    "    conv2 = Conv1D(filters=150, padding='same', \n",
    "                       kernel_size=n_features)(conv1)\n",
    "    conv3 = Conv1D(filters=100,padding='same', \n",
    "                   kernel_size=n_features)(conv2)\n",
    "    conv4 = Conv1D(filters=50, padding='same',\n",
    "                   kernel_size=n_features)(conv3)\n",
    "    conv5 = Conv1D(filters=latent_dim, padding='same',\n",
    "                       kernel_size=n_features)(conv4)\n",
    "    \n",
    "    z_mean = Dense(latent_dim, name='z_mean')(conv5)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(conv5)\n",
    "    \n",
    "    # Use those parameters to sample new points from the latent space:\n",
    "    # reparameterization trick\n",
    "    # instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "    # z = z_mean + sqrt(var) * epsilon\n",
    "    def sampling(args):\n",
    "        \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "        # Arguments\n",
    "            args (tensor): mean and log of variance of Q(z|X)\n",
    "        # Returns\n",
    "            z (tensor): sampled latent vector\n",
    "        \"\"\"\n",
    "    \n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        # by default, random_normal has mean = 0 and std = 1.0\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "      \n",
    "    # use reparameterization trick to push the sampling out as input\n",
    "    # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    # Instantiate the encoder model:\n",
    "    encoder = Model(inputs, z_mean) #z_mean\n",
    "    \n",
    "    # Build the decoder model:\n",
    "    latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "    x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "    outputs = Dense(n_features)(x)\n",
    "    \n",
    "    # Instantiate the decoder model:\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    \n",
    "    # Instantiate the VAE model:\n",
    "    outputs = decoder(encoder(inputs))\n",
    "    vae = Model(inputs, outputs, name='vae_mlp')\n",
    "    \n",
    "    # As in the Keras tutorial, we define a custom loss function:\n",
    "    \n",
    "    def vae_loss(x, x_decoded_mean):\n",
    "        xent_loss = losses.mean_squared_error(x, x_decoded_mean)\n",
    "        kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), \n",
    "                                 axis=-1)\n",
    "        return xent_loss + beta*kl_loss\n",
    "    \n",
    "    # We compile the model:\n",
    "    vae.compile(optimizer='adam', loss=vae_loss, metrics=['accuracy'])\n",
    "    \n",
    "    # Finally, we train the model:\n",
    "    results = vae.fit(normal_data, normal_data,\n",
    "            shuffle=True,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size)\n",
    "    \n",
    "    return vae, encoder, decoder\n",
    "\n",
    "vae, enc, dec = create_vae(beta=beta)\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_16: expected ndim=3, found ndim=2",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a551376dc873>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m \u001b[0mvae\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_vae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-a551376dc873>\u001b[0m in \u001b[0;36mcreate_vae\u001b[1;34m(beta)\u001b[0m\n\u001b[0;32m      8\u001b[0m     conv1 = Conv1D(filters=200, \n\u001b[0;32m      9\u001b[0m                    \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                    kernel_size=n_features)(inputs)\n\u001b[0m\u001b[0;32m     11\u001b[0m     conv2 = Conv1D(filters=150, padding='same', \n\u001b[0;32m     12\u001b[0m                        kernel_size=n_features)(conv1)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    312\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_16: expected ndim=3, found ndim=2"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "def check_disentanglement(weight_modifiers):\n",
    "    nom_enc = []\n",
    "    for i, elem in enumerate(vae_list):\n",
    "         print(\"ENCODING:\", i+1)\n",
    "         nom_enc.append(elem[1].predict(normal_data))\n",
    "         \n",
    "    # print(len(nom_enc))\n",
    "    \n",
    "    # print(len(nom_enc), nom_enc[0].shape)\n",
    "    nom_enc_modified = nom_enc\n",
    "    ##Modifiing values of the 1 neuron\n",
    "    for i, elem in enumerate(nom_enc_modified):\n",
    "        nom_enc_modified[i] = elem * weight_modifiers\n",
    "    # print(len(nom_enc_modified), nom_enc_modified[0].shape)\n",
    "    \n",
    "    \n",
    "    \n",
    "    nom_dec = []\n",
    "    for i, elem in enumerate(vae_list):\n",
    "         print(\"DECODING:\", i+1)\n",
    "         nom_dec.append(elem[2].predict(nom_enc_modified[i]))\n",
    "         \n",
    "    # print(len(nom_dec),nom_dec[0].shape)\n",
    "    \n",
    "    df_nominal = pd.DataFrame(normal_data, columns=boat_csv.columns)\n",
    "    \n",
    "    for i, elem in enumerate(nom_dec):\n",
    "        df = pd.DataFrame(elem, columns=boat_csv.columns)\n",
    "    \n",
    "        plt.subplot(421)\n",
    "        plt.plot(df[\"Lon\"][:5739])\n",
    "        plt.plot(df_nominal[\"Lon\"][:5739], 'r')\n",
    "        plt.title(\"Longitude\")\n",
    "        \n",
    "        plt.subplot(422)\n",
    "        plt.plot(df[\"Lat\"][:5739])\n",
    "        plt.plot(df_nominal[\"Lat\"][:5739], 'r')\n",
    "        plt.title(\"latitude\")\n",
    "        \n",
    "        plt.subplot(423)\n",
    "        plt.plot(df[\"Speed\"][:5739])\n",
    "        plt.plot(df_nominal[\"Speed\"][:5739], 'r')\n",
    "        plt.title(\"Speed\")        \n",
    "\n",
    "        plt.subplot(424)\n",
    "        plt.plot(df[\"Acceleration\"][:5739])\n",
    "        plt.plot(df_nominal[\"Acceleration\"][:5739], 'r')\n",
    "        plt.title(\"Acceleration\")         \n",
    "        \n",
    "        plt.subplot(425)\n",
    "        plt.plot(df[\"Degrees\"][:5739])\n",
    "        plt.plot(df_nominal[\"Degrees\"][:5739], 'r')\n",
    "        plt.title(\"Degrees\")           \n",
    "        \n",
    "        plt.subplot(426)\n",
    "        plt.plot(df[\"M0C\"][:5739])\n",
    "        plt.plot(df_nominal[\"M0C\"][:5739], 'r')\n",
    "        plt.title(\"M0C\")\n",
    "                \n",
    "        plt.subplot(427)\n",
    "        plt.plot(df[\"M1C\"][:5739])\n",
    "        plt.plot(df_nominal[\"M1C\"][:5739], 'r')\n",
    "        plt.title(\"M1C\")\n",
    "         \n",
    "        plt.show()\n",
    "        \n",
    "        plt.subplot(421)\n",
    "        plt.plot(df[\"Lon\"][:5739] - df_nominal[\"Lon\"][:5739])\n",
    "        plt.title(\"Longitude_difference\")\n",
    "        \n",
    "        plt.subplot(422)\n",
    "        plt.plot(df[\"Lat\"][:5739] - df_nominal[\"Lat\"][:5739])\n",
    "        plt.title(\"latitude_difference\")\n",
    "        \n",
    "        plt.subplot(423)\n",
    "        plt.plot(df[\"Speed\"][:5739] - df_nominal[\"Speed\"][:5739])\n",
    "        plt.title(\"Speed_difference\")        \n",
    "\n",
    "        plt.subplot(424)\n",
    "        plt.plot(df[\"Acceleration\"][:5739] - df_nominal[\"Acceleration\"][:5739])\n",
    "        plt.title(\"Acceleration_difference\")         \n",
    "        \n",
    "        plt.subplot(425)\n",
    "        plt.plot(df[\"Degrees\"][:5739] - df_nominal[\"Degrees\"][:5739])\n",
    "        plt.title(\"Degrees_difference\")           \n",
    "        \n",
    "        plt.subplot(426)\n",
    "        plt.plot(df[\"M0C\"][:5739] - df_nominal[\"M0C\"][:5739])\n",
    "        plt.title(\"M0C_difference\")\n",
    "                \n",
    "        plt.subplot(427)\n",
    "        plt.plot(df[\"M1C\"][:5739] - df_nominal[\"M1C\"][:5739])\n",
    "        plt.title(\"M1C_difference\")\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECODING: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weight_modifiers = np.ones(shape=(latent_dim,))\n",
    "weight_modifiers[-1] = 1\n",
    "check_disentanglement(weight_modifiers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "columns = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \"C6\", \"C7\", \"C8\", \"C9\", \"C10\"]\n",
    "for i, elem in enumerate(nom_enc):\n",
    "    column = \"C1\"\n",
    "    df_nominal = pd.DataFrame(elem, columns=columns)\n",
    "    for j in columns:\n",
    "        plt.plot(df_nominal[j])\n",
    "    plt.title(\"Column = \"+str(column) + \" Beta = \"+ str(beta_values[i]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoded_nominal = vae.predict(normal_data)\n",
    "print(autoencoded_nominal.shape)\n",
    "print(\"NOMINAL BEHAVIOUR PREDICTED\")\n",
    "autoencoded_anomalous = vae.predict(anomalous_data)\n",
    "print(autoencoded_anomalous.shape)\n",
    "print(\"ANOMALOUS BEHAVIOUR PREDICTED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nominal_reconstr_error(n_nominals):\n",
    "    r_err_nom_seq = []\n",
    "    SIGMAs = []\n",
    "    for i in range(0,len(normal_data), 5739):\n",
    "        nominal_data = normal_data[i:i+5739]\n",
    "        enc_nominal = autoencoded_nominal[i:i+5739]\n",
    "        diff = abs(nominal_data - enc_nominal)\n",
    "        r_err_nom_seq += [diff]\n",
    "        SIGMAs.append(np.cov(r_err_nom_seq[-1], rowvar=False))        \n",
    "        \n",
    "    r_err_nom_seq = np.array(r_err_nom_seq)\n",
    "    r_err_nom_seq = np.mean(r_err_nom_seq, axis=0)\n",
    "    mu = np.mean(r_err_nom_seq, axis=0)\n",
    "    SIGMAs = np.array(SIGMAs)\n",
    "    SIGMA = np.mean(SIGMAs, axis=0)\n",
    "    \n",
    "    print(mu.shape)\n",
    "    print(SIGMA.shape)\n",
    "    \n",
    "    return r_err_nom_seq,mu, SIGMA\n",
    "\n",
    "def calculate_anom_reconstr_error():\n",
    "    return abs(anomalous_data - autoencoded_anomalous)\n",
    "    \n",
    "       \n",
    "nom_errors, MU, SIGMA = calculate_nominal_reconstr_error(10)\n",
    "anom_error = calculate_anom_reconstr_error()\n",
    "print(anom_error.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_anomaly_score_sequence(i, element):\n",
    "    weights = [1, 1, 1, 1, 1, 100, 100]\n",
    "    score = np.dot(np.transpose(element-MU)*weights, \n",
    "                   np.dot(SIGMA, \n",
    "                  (element-MU)*weights))          \n",
    "    return score\n",
    "\n",
    "\n",
    "def get_anom_scores_nominal():\n",
    "    anom_scores = []\n",
    "    for i, element in enumerate(nom_errors):\n",
    "        anom_scores.append(calculate_anomaly_score_sequence(i, element))\n",
    "    return anom_scores\n",
    "\n",
    "\n",
    "def get_anom_scores():\n",
    "    anom_scores = []\n",
    "    for i, element in enumerate(anom_error):\n",
    "        anom_scores.append(calculate_anomaly_score_sequence(i, element))\n",
    "    return anom_scores\n",
    "\n",
    "\n",
    "scores_list = np.array(get_anom_scores())\n",
    "nom_scores_list = np.array(get_anom_scores_nominal())\n",
    "#plt.plot(scores_list)\n",
    "plt.plot(nom_scores_list)\n",
    "plt.show()\n",
    "\n",
    "#score_difference = abs(scores_list - nom_scores_list)\n",
    "# plt.plot(score_difference)\n",
    "# plt.show()\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectOutliers(x, outlierConstant):\n",
    "    a = np.array(x)\n",
    "    upper_quartile = np.percentile(a, 75)\n",
    "    lower_quartile = np.percentile(a, 25)\n",
    "    IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    resultList = []\n",
    "    outlierList = []\n",
    "    \n",
    "    list = a.tolist()\n",
    "    for y in range(len(list)):\n",
    "        if list[y] >= quartileSet[0] and list[y] <= quartileSet[1]:\n",
    "            resultList.append(list[y])\n",
    "        else:\n",
    "            outlierList.append((y,list[y]))\n",
    "            resultList.append(list[y-1])\n",
    "    return  outlierList\n",
    "\n",
    "\n",
    "outliers_anomalous_list = detectOutliers(scores_list,\n",
    "                                         outlierConstant=10)\n",
    "\n",
    "print(len(outliers_anomalous_list))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "an_csv = pd.read_csv(\"Data/Anomalous_boat_data.csv\")\n",
    "an_csv = an_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "plt.plot(an_csv[\"longitude\"], an_csv[\"latitude\"])\n",
    "plt.title(\"Nominal anoamalies points Autoenc_Big\")\n",
    "for i in outliers_anomalous_list:\n",
    "    anomaly_position = i[0]\n",
    "    plt.plot(an_csv[\"longitude\"][anomaly_position],\n",
    "             an_csv[\"latitude\"][anomaly_position], 'bo')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nominal = pd.DataFrame(autoencoded_nominal, columns=boat_csv.columns)\n",
    "df_anomalous = pd.DataFrame(autoencoded_anomalous, columns=boat_csv.columns)\n",
    "\n",
    "plt.plot(df_nominal[\"Lon\"][:5739], df_nominal[\"Lat\"][:5739])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(df_anomalous[\"Lon\"], df_anomalous[\"Lat\"])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
