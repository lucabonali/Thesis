{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5700, 7)\n(5700, 7)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.layers import LSTM, RepeatVector\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "import keras as kr\n",
    "\n",
    "\n",
    "def read_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "boat_csv = read_data(\"Data/Boat_data.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "boat_csv = boat_csv.drop(boat_csv.index[-39:])\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "# boat_csv = read_data(\"Data/Anomalous_boat_data.csv\")\n",
    "# boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\", \"heading\"])\n",
    "# boat_csv = boat_csv.drop(boat_csv.index[-20:])    \n",
    "# scaler = StandardScaler()\n",
    "# anomalous_data = scaler.fit_transform(boat_csv)\n",
    "# print(anomalous_data.shape)\n",
    "\n",
    "\n",
    "boat_csv = read_data(\"Data/Boat_data_curved.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "boat_csv = boat_csv.drop(boat_csv.index[-39:])    \n",
    "scaler = StandardScaler()\n",
    "anomalous_data = scaler.fit_transform(boat_csv)\n",
    "print(anomalous_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 150, 7)\n(370, 150, 7)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 150\n",
    "interval = 15\n",
    "\n",
    "def prepare_sequences(data):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0]-batch_size, interval):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "        \n",
    "    sequences = np.array(samples)\n",
    "    \n",
    "    # Batch size (Number of samples time steps and number of features\n",
    "    trainX = np.reshape(sequences, (len(samples), batch_size, 7))\n",
    "    \n",
    "    return trainX\n",
    "\n",
    "trainX_nominal = prepare_sequences(normal_data) \n",
    "print(trainX_nominal.shape)\n",
    "\n",
    "trainX_anomalous = prepare_sequences(anomalous_data)\n",
    "print(trainX_anomalous.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING the model\nCOMPILING\nFITTING\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 18s - loss: 0.9503 - acc: 0.2067"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 30s 81ms/step - loss: 0.9634 - acc: 0.2463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 6s - loss: 0.9042 - acc: 0.3245"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 12s 34ms/step - loss: 0.8897 - acc: 0.3282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 7s - loss: 0.8504 - acc: 0.3593"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 27s 74ms/step - loss: 0.8346 - acc: 0.3388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 5s - loss: 0.8331 - acc: 0.3316"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 13s 35ms/step - loss: 0.7967 - acc: 0.3349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 6s - loss: 0.8062 - acc: 0.3260"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 14s 37ms/step - loss: 0.7710 - acc: 0.3362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 4s - loss: 0.7385 - acc: 0.3271"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 12s 33ms/step - loss: 0.7479 - acc: 0.3362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 3s - loss: 0.7192 - acc: 0.3622"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 8s 23ms/step - loss: 0.7275 - acc: 0.3503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 2s - loss: 0.7110 - acc: 0.3752"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 9s 24ms/step - loss: 0.7138 - acc: 0.3521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 1s - loss: 0.7005 - acc: 0.3562"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 4s 11ms/step - loss: 0.7027 - acc: 0.3739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r200/370 [===============>..............] - ETA: 2s - loss: 0.6956 - acc: 0.3874"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r370/370 [==============================] - 7s 19ms/step - loss: 0.6916 - acc: 0.4030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#TRAINING MODEL\n",
    "timesteps=batch_size\n",
    "input_dim=7\n",
    "batch_size = batch_size\n",
    "epochs=10\n",
    "\n",
    "def get_model(n_dimensions):\n",
    "    encoder = Sequential(name=\"encode\")\n",
    "    encoder.add(LSTM(timesteps,return_sequences=True))\n",
    "    encoder.add(LSTM(64,return_sequences=False))\n",
    "    encoder.add(Dense(7))\n",
    "    \n",
    "\n",
    "    decoder = Sequential(name=\"decode\")\n",
    "    decoder.add(Dense(7))\n",
    "    decoder.add(Dense(64))\n",
    "    decoder.add(RepeatVector(timesteps))\n",
    "    decoder.add(LSTM(input_dim, return_sequences=True))\n",
    "    \n",
    "    autoencoder = Sequential()\n",
    "    \n",
    "    autoencoder.add(encoder)\n",
    "    autoencoder.add(decoder)\n",
    "    \n",
    "    return autoencoder\n",
    "\n",
    "print(\"GETTING the model\")\n",
    "autoencoder = get_model(7)\n",
    "print(\"COMPILING\")\n",
    "autoencoder.compile(optimizer='adam', loss='mse',\n",
    "                    metrics=['accuracy'])\n",
    "print(\"FITTING\")\n",
    "history = autoencoder.fit(trainX_nominal, trainX_nominal, batch_size=200, \n",
    "                          epochs=epochs)\n",
    "\n",
    "autoencoder.save(\"Models/Nominal_LSTM.model\")\n",
    "#autoencoder.save(\"Models/Anomalous_LSTM.model\")\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal MODEL LOADED\n"
     ]
    }
   ],
   "source": [
    "#LOADING MODEL\n",
    "\n",
    "nom_model = kr.models.load_model(\"Models/Nominal_LSTM.model\")\n",
    "print(\"Nominal MODEL LOADED\")\n",
    "\n",
    "#anom_model = kr.models.load_model(\"Models/Anomalous_LSTM.model\")\n",
    "\n",
    "#print(\"Anomalous MODEL LOADED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded_sequences = nom_model.get_layer(\"encode\").predict(trainX_nominal)\n",
    "encoded_anomalous = nom_model.get_layer(\"encode\").predict(trainX_anomalous)\n",
    "\n",
    "weights = [1, 1, 1, 0.01, 0.01, 10, 10]\n",
    "\n",
    "weighted_nominal = np.average(encoded_sequences, axis=1, weights=weights)\n",
    "weighted_anomalous = np.average(encoded_anomalous, axis=1, weights=weights)\n",
    "\n",
    "plt.plot(weighted_nominal)\n",
    "plt.plot(weighted_anomalous)\n",
    "plt.show()\n",
    "\n",
    "encoded_difference = abs(weighted_nominal - weighted_anomalous)\n",
    "plt.plot(encoded_difference)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 150, 7)\nNOMINAL BEHAVIOUR PREDICTED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 150, 7)\nANOMALOUS BEHAVIOUR PREDICTED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoded_nominal = nom_model.predict(trainX_nominal)\n",
    "print(autoencoded_nominal.shape)\n",
    "print(\"NOMINAL BEHAVIOUR PREDICTED\")\n",
    "autoencoded_anomalous = nom_model.predict(trainX_anomalous)\n",
    "print(autoencoded_anomalous.shape)\n",
    "print(\"ANOMALOUS BEHAVIOUR PREDICTED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Speed   Degrees  Accelleration       M0C       M1C     G_Lat     G_Lon\n0    0.076726  0.071785       0.017887 -0.028505  0.010975 -0.094534  0.063530\n1    0.139438  0.115148       0.024008 -0.051385  0.015487 -0.152509  0.101309\n2    0.187301  0.140101       0.022142 -0.069328  0.016931 -0.187229  0.124463\n3    0.222733  0.154401       0.015314 -0.083131  0.017346 -0.208237  0.139275\n4    0.248807  0.162730       0.005727 -0.093612  0.017789 -0.221171  0.149068\n..        ...       ...            ...       ...       ...       ...       ...\n145  0.343139  0.178741      -0.105296 -0.126746  0.057707 -0.236987  0.170955\n146  0.343139  0.178741      -0.105296 -0.126746  0.057707 -0.236987  0.170955\n147  0.343139  0.178741      -0.105296 -0.126746  0.057707 -0.236987  0.170955\n148  0.343139  0.178741      -0.105296 -0.126746  0.057707 -0.236987  0.170955\n149  0.343139  0.178741      -0.105296 -0.126746  0.057707 -0.236987  0.170955\n\n[150 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(autoencoded_nominal[0], columns=boat_csv.columns)\n",
    "print(df)\n",
    "\n",
    "plt.plot(df[\"G_Lon\"], df[\"G_Lat\"])\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 150\n370 [0.64998688 0.82457992 0.80585707 0.54642542 0.61807395 1.02175651\n 0.4391662 ]\nSIGMA 370 7 7\nDone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "anomalous_sequences = []\n",
    "reconstr_error_nominal_sequences, reconstr_error_anomalous_sequences = [], []\n",
    "MUs, SIGMAs = [], []\n",
    "window = batch_size\n",
    "interval = interval\n",
    "cont = 0\n",
    "\n",
    "for i in autoencoded_nominal:\n",
    "    reconstr_error_nominal_sequences.append(abs(normal_data[cont:cont+window] - i))\n",
    "    cont += interval\n",
    "    MUs.append(np.average(reconstr_error_nominal_sequences[-1], axis=0))\n",
    "    SIGMAs.append(np.cov(reconstr_error_nominal_sequences[-1], rowvar=False))\n",
    "    \n",
    "cont = 0\n",
    "for j in autoencoded_anomalous:\n",
    "    reconstr_error_anomalous_sequences.append(abs(anomalous_data[cont:cont+window] - j))\n",
    "    cont += interval\n",
    "\n",
    "print(len(reconstr_error_nominal_sequences), len(reconstr_error_nominal_sequences[0]))\n",
    "print(len(MUs), MUs[0])\n",
    "print(\"SIGMA\",len(SIGMAs),len(SIGMAs[0]), len(SIGMAs[0][0]))\n",
    "print(\"Done\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 370\n"
     ]
    }
   ],
   "source": [
    "def calculate_anomaly_score_sequence(i, element):\n",
    "    scores = []\n",
    "    weights = [1, 1, 1, 0.01, 0.01, 10, 10]\n",
    "    for j, elem in enumerate(element):\n",
    "        score = np.dot(np.transpose(element[j]-MUs[i])*weights, \n",
    "                       np.dot(SIGMAs[i], \n",
    "                            (element[j]-MUs[i])*weights))      \n",
    "        scores.append(score)\n",
    "    return np.average(scores)\n",
    "\n",
    "\n",
    "anomaly_scores = []\n",
    "\n",
    "for i, element in enumerate(reconstr_error_anomalous_sequences):\n",
    "    anomaly_scores.append(calculate_anomaly_score_sequence(i, element))\n",
    "\n",
    "anomaly_scores_nominal = []\n",
    "for i, element in enumerate(reconstr_error_nominal_sequences):\n",
    "    anomaly_scores_nominal.append(calculate_anomaly_score_sequence(i, element))\n",
    "\n",
    "print(len(anomaly_scores), len(anomaly_scores_nominal))\n",
    "\n",
    "a = np.array(anomaly_scores_nominal)\n",
    "b = np.array(anomaly_scores)\n",
    "anom_scores = abs(a - b)\n",
    "\n",
    "plt.plot(anomaly_scores)\n",
    "plt.plot(anomaly_scores_nominal)\n",
    "plt.show()\n",
    "plt.plot(anom_scores)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(anom_scores)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\nDone\n"
     ]
    }
   ],
   "source": [
    "def detectOutliers(x, outlierConstant):\n",
    "    a = np.array(x)\n",
    "    upper_quartile = np.percentile(a, 75)\n",
    "    lower_quartile = np.percentile(a, 25)\n",
    "    IQR = (upper_quartile - lower_quartile) * outlierConstant\n",
    "    quartileSet = (lower_quartile - IQR, upper_quartile + IQR)\n",
    "    resultList = []\n",
    "    outlierList = []\n",
    "    \n",
    "    list = a.tolist()\n",
    "    for y in range(len(list)):\n",
    "        if list[y] >= quartileSet[0] and list[y] <= quartileSet[1]:\n",
    "            resultList.append(list[y])\n",
    "        else:\n",
    "            outlierList.append((y,list[y]))\n",
    "            resultList.append(list[y-1])\n",
    "    return resultList, outlierList\n",
    "\n",
    "#nominal_without_outliers, outlier_list = detectOutliers(anomaly_scores_nominal,\n",
    "#                                                        outlierConstant=20)\n",
    "\n",
    "anomalous_without_outliers, outliers_anomalous_list = detectOutliers(encoded_difference,\n",
    "                                                                    outlierConstant=25)\n",
    "\n",
    "print(len(outliers_anomalous_list))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PLOT THE GRAPHS AND OUTLINE THE POINTS OF THE SUSPECTED ANOMALIES\n",
    "\n",
    "# \n",
    "# boat_csv = read_data(\"Data/Boat_data.csv\")\n",
    "# boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "# \n",
    "# plt.plot(boat_csv[\"G_Lon\"], boat_csv[\"G_Lat\"])\n",
    "# plt.title(\"Nominal anoamalies points LSTM_AE\")\n",
    "# for i in outlier_list:\n",
    "#     anomaly_position = i[0]*interval \n",
    "#     plt.plot(boat_csv[\"G_Lon\"][anomaly_position:anomaly_position+window],\n",
    "#              boat_csv[\"G_Lat\"][anomaly_position:anomaly_position+window], 'bo')\n",
    "# \n",
    "# plt.show()\n",
    "\n",
    "\n",
    "an_csv = read_data(\"Data/Boat_data_curved.csv\")\n",
    "an_csv = an_csv.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "plt.plot(an_csv[\"G_Lon\"], an_csv[\"G_Lat\"])\n",
    "plt.title(\"Nominal anoamalies points LSTM_AE\")\n",
    "for i in outliers_anomalous_list:\n",
    "    anomaly_position = i[0] * interval \n",
    "    plt.plot(an_csv[\"G_Lon\"][anomaly_position:anomaly_position+window],\n",
    "             an_csv[\"G_Lat\"][anomaly_position:anomaly_position+window], 'bo')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 150, 7)\n        Speed   Degrees  Accelleration       M0C       M1C     G_Lat     G_Lon\n0    0.103706  0.053368      -0.003267 -0.033263  0.015652 -0.199269  0.089458\n1    0.147910  0.088868      -0.000346 -0.055080  0.016915 -0.322113  0.136497\n2    0.165159  0.112554       0.004585 -0.069299  0.013441 -0.395346  0.161763\n3    0.171146  0.128592       0.009500 -0.078585  0.008989 -0.439709  0.175953\n4    0.172714  0.139658       0.013663 -0.084588  0.004908 -0.467474  0.184227\n..        ...       ...            ...       ...       ...       ...       ...\n145  0.169906  0.166844       0.024126 -0.089409 -0.008423 -0.527643  0.195545\n146  0.169906  0.166844       0.024126 -0.089409 -0.008423 -0.527643  0.195545\n147  0.169906  0.166844       0.024126 -0.089409 -0.008423 -0.527643  0.195545\n148  0.169906  0.166844       0.024126 -0.089409 -0.008423 -0.527643  0.195545\n149  0.169906  0.166844       0.024126 -0.089409 -0.008423 -0.527643  0.195545\n\n[150 rows x 7 columns]\nEnd\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# nominal = True\n",
    "# print(autoencoded_nominal.shape)\n",
    "# \n",
    "# autoenc_df = pd.DataFrame(autoencoded_nominal[0], columns= boat_csv.columns)\n",
    "# print(autoenc_df)\n",
    "# \n",
    "# if nominal:\n",
    "#     plt.plot(boat_csv[\"Speed\"])\n",
    "#     plt.plot(autoenc_df['Speed'])\n",
    "#     plt.show()\n",
    "# else:\n",
    "#     plt.plot(boat_csv[\"speed\"])\n",
    "#     plt.plot(autoenc_df[\"speed\"])\n",
    "#     plt.show()\n",
    "# print(\"End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
