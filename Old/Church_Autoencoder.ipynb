{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x        y         z  speed  acceleration     degrees\n0      19.6375  119.519  1.055533    0.0           0.0  180.763076\n1      19.6375  119.519  1.055533    0.0           0.0  180.766938\n2      19.6375  119.519  1.055533    0.0           0.0  179.907911\n3      19.6375  119.519  1.055533    0.0           0.0  178.959499\n4      19.6375  119.519  1.055533    0.0           0.0  178.292871\n...        ...      ...       ...    ...           ...         ...\n17645  19.6167  119.761  1.077899    0.0           0.0  180.476128\n17646  19.6167  119.761  1.077899    0.0           0.0  171.826245\n17647  19.6167  119.761  1.077899    0.0           0.0  146.341278\n17648  19.6167  119.761  1.077899    0.0           0.0   93.364190\n17649  19.6167  119.761  1.077899    0.0           0.0    0.002950\n\n[17650 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def read_data(data_path):\n",
    "    data = pd.read_csv(data_path)\n",
    "    return data\n",
    "\n",
    "run_csv = read_data(\"Data/Church_csv/1^_RUN.csv\")\n",
    "run_csv = run_csv.drop(columns=[\"Unnamed: 0\",\"seconds\"])\n",
    "print(run_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.67520988e+00  7.37636972e-01  1.33261902e-01 -2.48580976e+00\n  -1.89462091e-03  2.22502721e-02]\n [-1.67520988e+00  7.37636972e-01  1.33261902e-01 -2.48580976e+00\n  -1.89462091e-03  2.22890518e-02]\n [-1.67520988e+00  7.37636972e-01  1.33261902e-01 -2.48580976e+00\n  -1.89462091e-03  1.36634841e-02]\n ...\n [-1.67592123e+00  7.45455320e-01  1.45880593e-01 -2.48580976e+00\n  -1.89462091e-03 -3.23382009e-01]\n [-1.67592123e+00  7.45455320e-01  1.45880593e-01 -2.48580976e+00\n  -1.89462091e-03 -8.55329594e-01]\n [-1.67592123e+00  7.45455320e-01  1.45880593e-01 -2.48580976e+00\n  -1.89462091e-03 -1.79277798e+00]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "run_csv = scaler.fit_transform(run_csv)\n",
    "print(run_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.40848981e+00  1.44637224e-03]\n [-2.40850054e+00  1.45815426e-03]\n [-2.40611331e+00 -1.16245937e-03]\n ...\n [-2.31816460e+00 -9.79743305e-02]\n [-2.17094159e+00 -2.59590254e-01]\n [-1.91149126e+00 -5.44405133e-01]]\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "logdir = \"tf_logs/\" + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=logdir)\n",
    "\n",
    "model = Sequential()\n",
    "encoder = Sequential(name=\"encoder\")\n",
    "encoder.add(Dense(256, input_dim=run_csv.shape[1], activation='relu'))\n",
    "encoder.add(Dense(128, activation=\"relu\"))\n",
    "encoder.add(Dense(64, activation='relu'))\n",
    "\n",
    "decoder = Sequential()\n",
    "decoder.add(Dense(64, activation='relu'))\n",
    "decoder.add(Dense(128, activation=\"relu\"))\n",
    "decoder.add(Dense(run_csv.shape[1], activation='relu'))\n",
    "\n",
    "model.add(encoder)\n",
    "model.add(decoder)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(run_csv,run_csv,verbose=1,epochs=10, validation_split=0.1,callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.40848981e+00  1.44637224e-03]\n [-2.40850054e+00  1.45815426e-03]\n [-2.40611331e+00 -1.16245937e-03]\n ...\n [-2.31816460e+00 -9.79743305e-02]\n [-2.17094159e+00 -2.59590254e-01]\n [-1.91149126e+00 -5.44405133e-01]]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "run_csv = scaler.fit_transform(run_csv)\n",
    "\n",
    "enc_input =run_csv # model.get_layer(name=\"encoder\").predict(run_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.40848981e+00  1.44637224e-03]\n [-2.40850054e+00  1.45815426e-03]\n [-2.40611331e+00 -1.16245937e-03]\n ...\n [-2.31816460e+00 -9.79743305e-02]\n [-2.17094159e+00 -2.59590254e-01]\n [-1.91149126e+00 -5.44405133e-01]]\n"
     ]
    }
   ],
   "source": [
    "pca=True\n",
    "\n",
    "if pca:\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(enc_input)\n",
    "    pca = PCA(n_components=2)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    print(principalComponents)\n",
    "    x_val = []\n",
    "    y_val=[]\n",
    "    for i in range(principalComponents.shape[0]):\n",
    "        x_val.append(principalComponents[i][0])\n",
    "        y_val.append(principalComponents[i][1])\n",
    "    \n",
    "    \n",
    "    plt.scatter(x=x_val,y=y_val, alpha=0.5)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "run2_csv = read_data(\"Data/Church_csv/2^_RUN.csv\")\n",
    "run2_csv = run2_csv.drop(columns=[\"Unnamed: 0\",\"seconds\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "run2_csv = scaler.fit_transform(run2_csv)\n",
    "\n",
    "enc_input = model.predict(run2_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "tsne_obj= tsne.fit_transform(enc_input)\n",
    "tsne_df = pd.DataFrame({'X':tsne_obj[:,0],\n",
    "                        'Y':tsne_obj[:,1],\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=tsne_df[\"X\"],y=tsne_df[\"Y\"], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
