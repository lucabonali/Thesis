{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from scipy.stats import norm\n",
    "# from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "# from keras.layers import Conv1D\n",
    "# from keras.models import Model\n",
    "# from keras import backend as K\n",
    "# from sklearn.utils import resample\n",
    "# \n",
    "# n_features = 4\n",
    "# n_runs = 200\n",
    "# labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_len_labels.csv\")\n",
    "# labels = labels.drop(columns=\"Unnamed: 0\") \n",
    "# labels = np.array(labels)\n",
    "# max_len = 0\n",
    "# \n",
    "# \n",
    "# \n",
    "# def prepare_training(path, n_runs):\n",
    "#     def closest_4(n, m):\n",
    "#         q = n / m\n",
    "#         n1 = m * q\n",
    "#         if (n * m) > 0:\n",
    "#             n2 = m * (q + 1)\n",
    "#         else:\n",
    "#             n2 = m * (q - 1)\n",
    "#         if abs(n-n1) < abs(n-n2):\n",
    "#             return int(n1)\n",
    "#         return int(n2)\n",
    "#     \n",
    "#     \n",
    "#     def extend_line(run, max_len):\n",
    "#         difference = abs(len(run) - max_len)\n",
    "#         extension = np.array([run[-1]]*difference)\n",
    "#         if difference != 0:\n",
    "#             run = np.vstack([run, extension])\n",
    "#         return run\n",
    "#     \n",
    "#     def get_max_len(sequence_list):\n",
    "#         max_len = 0\n",
    "#         min_len = 1000\n",
    "#         for seq in sequence_list:\n",
    "#             if len(seq) > max_len:\n",
    "#                 max_len = len(seq)\n",
    "#             if len(seq) < min_len:\n",
    "#                 min_len = len(seq)\n",
    "#         return max_len, min_len\n",
    "#     \n",
    "#     def construct_matrix(sequence_list):\n",
    "#         max_len, min_len = get_max_len(sequence_list)\n",
    "#         print(max_len)\n",
    "#         len = closest_4(max_len,4)\n",
    "#         len = 620\n",
    "#         train_matrix = np.zeros(shape=(n_runs, len, n_features))\n",
    "#         for index, run in enumerate(sequence_list):\n",
    "#             line = extend_line(run, len)\n",
    "#             train_matrix[index] = line\n",
    "#         return train_matrix\n",
    "#         \n",
    "#         \n",
    "#     def stadard_sequences(seqs):\n",
    "#         for i, seq in enumerate(seqs):\n",
    "#             seqs[i] = MinMaxScaler(feature_range=[0, 1]).fit_transform(seq)\n",
    "#         return seqs       \n",
    "#     \n",
    "#     \n",
    "#     def read_sequences():\n",
    "#         run_list_mix = []\n",
    "#         for index in range(n_runs):\n",
    "#             run_csv = pd.read_csv(path+str(index))\n",
    "#             run_csv = run_csv.drop(columns=['Unnamed: 0'])\n",
    "#             run_list_mix.append(run_csv)\n",
    "#         stands = stadard_sequences(run_list_mix)\n",
    "#         padded_matrix = construct_matrix(stands)\n",
    "#         return padded_matrix\n",
    "#     \n",
    "#     return read_sequences()\n",
    "#     \n",
    "# \n",
    "# train_matrix = prepare_training(\"Mix_sequences_var_length/run^\", n_runs=n_runs) \n",
    "# print(train_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "607\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.utils import resample\n",
    "\n",
    "n_features = 4\n",
    "latent_dim = 10\n",
    "n_runs = 300\n",
    "max_len = 0\n",
    "\n",
    "def prepare_training(path, n_runs):\n",
    "    labels = []\n",
    "    def closest_4(n, m):\n",
    "        q = n / m\n",
    "        n1 = m * q\n",
    "        if (n * m) > 0:\n",
    "            n2 = m * (q + 1)\n",
    "        else:\n",
    "            n2 = m * (q - 1)\n",
    "        if abs(n-n1) < abs(n-n2):\n",
    "            return int(n1)\n",
    "        return int(n2)\n",
    "    \n",
    "    \n",
    "    def extend_line(run, max_len):\n",
    "        difference = abs(len(run) - max_len)\n",
    "        extension = np.array([run[-1]]*difference)\n",
    "        if difference != 0:\n",
    "            run = np.vstack([run, extension])\n",
    "        return run\n",
    "    \n",
    "    def get_max_len(sequence_list):\n",
    "        max_len = 0\n",
    "        min_len = 1000\n",
    "        for seq in sequence_list:\n",
    "            if len(seq) > max_len:\n",
    "                max_len = len(seq)\n",
    "            if len(seq) < min_len:\n",
    "                min_len = len(seq)\n",
    "        return max_len, min_len\n",
    "    \n",
    "    def construct_matrix(sequence_list):\n",
    "        max_len, min_len = get_max_len(sequence_list)\n",
    "        print(max_len)\n",
    "        len = closest_4(max_len,4)\n",
    "        len = 620\n",
    "        train_matrix = np.zeros(shape=(n_runs, len, n_features))\n",
    "        for index, run in enumerate(sequence_list):\n",
    "            line = extend_line(run, len)\n",
    "            train_matrix[index] = line\n",
    "        return train_matrix\n",
    "        \n",
    "        \n",
    "    def stadard_sequences(seqs):\n",
    "        for i, seq in enumerate(seqs):\n",
    "            seqs[i] = MinMaxScaler(feature_range=[0, 1]).fit_transform(seq)\n",
    "        return seqs       \n",
    "    \n",
    "    \n",
    "    def order_runs_by_len(runs):\n",
    "        runs.sort(key=len)\n",
    "        for r in runs:\n",
    "            labels.append(r['Choice'][0])\n",
    "        for i,r in enumerate(runs):\n",
    "            runs[i] = runs[i].drop(columns=['Choice'])\n",
    "        return runs, labels\n",
    "    \n",
    "    def read_sequences():\n",
    "        run_list_mix = []\n",
    "        for index in range(n_runs):\n",
    "            run_csv = pd.read_csv(path+str(index))\n",
    "            run_csv = run_csv.drop(columns=['Unnamed: 0'])\n",
    "            run_list_mix.append(run_csv)\n",
    "        run_list_ordered, labels = order_runs_by_len(run_list_mix)\n",
    "        stands = stadard_sequences(run_list_ordered)\n",
    "        padded_matrix = construct_matrix(stands)\n",
    "        return padded_matrix, labels\n",
    "    \n",
    "    return read_sequences()\n",
    "\n",
    "train_matrix, labels = prepare_training(\"Mix_sequences_var_length/run^\", n_runs=n_runs) \n",
    "labels = np.array(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nVae_input (InputLayer)          (None, 620, 4)       0                                            \n__________________________________________________________________________________________________\nconv1d_62 (Conv1D)              (None, 620, 40)      3240        Vae_input[0][0]                  \n__________________________________________________________________________________________________\nmax_pooling1d_44 (MaxPooling1D) (None, 310, 40)      0           conv1d_62[0][0]                  \n__________________________________________________________________________________________________\nconv1d_63 (Conv1D)              (None, 310, 40)      32040       max_pooling1d_44[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_45 (MaxPooling1D) (None, 155, 40)      0           conv1d_63[0][0]                  \n__________________________________________________________________________________________________\nconv1d_64 (Conv1D)              (None, 155, 40)      32040       max_pooling1d_45[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_46 (MaxPooling1D) (None, 77, 40)       0           conv1d_64[0][0]                  \n__________________________________________________________________________________________________\nconv1d_65 (Conv1D)              (None, 77, 40)       32040       max_pooling1d_46[0][0]           \n__________________________________________________________________________________________________\nmax_pooling1d_47 (MaxPooling1D) (None, 38, 40)       0           conv1d_65[0][0]                  \n__________________________________________________________________________________________________\ndec_input (InputLayer)          (None, 620, 4)       0                                            \n__________________________________________________________________________________________________\nlstm_41 (LSTM)                  [(None, 10), (None,  2040        max_pooling1d_47[0][0]           \n__________________________________________________________________________________________________\nlstm_42 (LSTM)                  (None, 620, 10)      600         dec_input[0][0]                  \n                                                                 lstm_41[0][1]                    \n                                                                 lstm_41[0][2]                    \n__________________________________________________________________________________________________\nlambda_81 (Lambda)              (None, 620, 1, 10)   0           lstm_42[0][0]                    \n__________________________________________________________________________________________________\nconv2d_transpose_41 (Conv2DTran (None, 620, 1, 40)   8040        lambda_81[0][0]                  \n__________________________________________________________________________________________________\nlambda_82 (Lambda)              (None, 620, 40)      0           conv2d_transpose_41[0][0]        \n__________________________________________________________________________________________________\nlambda_83 (Lambda)              (None, 620, 1, 40)   0           lambda_82[0][0]                  \n__________________________________________________________________________________________________\nconv2d_transpose_42 (Conv2DTran (None, 620, 1, 40)   32040       lambda_83[0][0]                  \n__________________________________________________________________________________________________\nlambda_84 (Lambda)              (None, 620, 40)      0           conv2d_transpose_42[0][0]        \n__________________________________________________________________________________________________\ndense_21 (Dense)                (None, 620, 4)       164         lambda_84[0][0]                  \n==================================================================================================\nTotal params: 142,244\nTrainable params: 142,244\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import objectives\n",
    "from keras.layers import Input, LSTM, RepeatVector, Conv2DTranspose, MaxPooling1D, UpSampling1D, AveragePooling1D\n",
    "from keras.losses import mse\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "filters = 40\n",
    "intermediate_dimension = 50 \n",
    "latent_dim = 10\n",
    "\n",
    "\n",
    "def Conv1DTranspose(input_tensor, filters, kernel_size,strides=1, padding='same'):\n",
    "        x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1),\n",
    "                            activation='relu',\n",
    "                            strides=strides, padding='same')(x)\n",
    "        x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim), mean=0., stddev=0.000001)\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "# \n",
    "# \n",
    "# def repeat(x):\n",
    "#     steps_matrix = K.ones_like(x[0][:, :, :1])\n",
    "#     \n",
    "#     latent_matrix = K.expand_dims(x[1], axis=1)\n",
    "#     return K.batch_dot(steps_matrix, latent_matrix)\n",
    "\n",
    "\n",
    "def create_vae():\n",
    "    inputs = Input(shape=(train_matrix.shape[1], n_features), name='Vae_input')\n",
    "    x = inputs\n",
    "    \n",
    "    for i in range(4):\n",
    "        x = Conv1D(filters=filters,\n",
    "                   kernel_size=20,\n",
    "                   activation='relu',\n",
    "                   padding='same')(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "\n",
    "\n",
    "            \n",
    "    encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(x)\n",
    "    encoder_states = [state_h, state_c]     \n",
    "    \n",
    "    z_mean = Dense(latent_dim, name='z_mean',)(state_h)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(state_h)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z, state_h, state_c], name='encoder')\n",
    "    # \n",
    "    #latent_inputs = Input(shape=(latent_dim,), name='latent_inputs')\n",
    "    # x_dec = Dense(shape[1]*shape[2])(z)\n",
    "    # x_dec = Reshape((shape[1], shape[2]))(x_dec)\n",
    "    \n",
    "    decoder_inputs = Input((train_matrix.shape[1], n_features), name='dec_input')\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True)\n",
    "    dec_lstm = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    # x_dec = Dense(shape[1]*shape[2])(dec_lstm)\n",
    "    # x_dec = Reshape((shape[1], shape[2]))(x_dec)\n",
    "    \n",
    "    x_dec = dec_lstm\n",
    "    for i in range(2):\n",
    "        x_dec = Conv1DTranspose(input_tensor=x_dec,\n",
    "                            filters=filters,\n",
    "                            kernel_size=20,\n",
    "                            padding='same')\n",
    "        #x_dec = UpSampling1D(size=2)(x_dec)\n",
    "        \n",
    "    output = Dense(n_features)(x_dec)\n",
    "    \n",
    "    # decoder = Model(latent_inputs, output)\n",
    "    # \n",
    "    # output = decoder(encoder.outputs[2])\n",
    "    # \n",
    "    \n",
    "    xent_loss = objectives.mean_squared_error(K.flatten(inputs), K.flatten(output))\n",
    "    kl_loss = 0.5 * K.sum(K.exp(z_log_var) + K.square(z_mean) - 1. - z_log_var, axis=1)\n",
    "    loss = K.mean(xent_loss+kl_loss)\n",
    "    vae = Model([inputs, decoder_inputs], output, name='vae')\n",
    "    vae.add_loss(loss)\n",
    "    vae.compile(optimizer='rmsprop')\n",
    "    vae.summary()\n",
    "    \n",
    "    return vae, encoder\n",
    "\n",
    "# \n",
    "# def create_ae():\n",
    "#     inputs = Input(shape=(train_matrix.shape[1], n_features))\n",
    "#     x = inputs\n",
    "#     for i in range(2):\n",
    "#         x = Conv1D(filters=filters, kernel_size=20,\n",
    "#                    activation='relu',\n",
    "#                    padding='same')(x)\n",
    "#         x = AveragePooling1D(pool_size=2)(x)\n",
    "#     shape = K.int_shape(x)   \n",
    "#     print(shape)\n",
    "#     x,_,_ = LSTM(intermediate_dimension, return_state=True)(x)\n",
    "#     #x = Flatten()(x)\n",
    "#     encoded = Dense(latent_dim)(x)\n",
    "#     #x = Lambda(repeat)([before_flattening, encoded])\n",
    "# \n",
    "#     latent_inputs = Input(shape=(latent_dim,), name='latent_inputs')\n",
    "#     x = Dense(shape[1]*shape[2])(latent_inputs)\n",
    "#     x = Reshape((shape[1],shape[2]))(x)\n",
    "#     \n",
    "#     x = LSTM(units=K.int_shape(x)[2],return_sequences=True)(x)\n",
    "#     for i in range(2):\n",
    "#         x = Conv1DTranspose(input_tensor=x, filters=filters,\n",
    "#                             kernel_size=20, padding='same')\n",
    "#         x = UpSampling1D(size=2)(x)\n",
    "# \n",
    "#     #decoded = LSTM(n_features, return_sequences=True)(x)\n",
    "# \n",
    "#     output = Dense(n_features)(x)\n",
    "# \n",
    "#     encoder = Model(inputs, encoded)\n",
    "#     encoder.summary()\n",
    "#     decoder = Model(latent_inputs, output)\n",
    "#     decoder.summary()\n",
    "#     output = decoder(encoder.output)\n",
    "#     sequence_autoencoder = Model(inputs, output)\n",
    "#     #sequence_autoencoder.summary()\n",
    "#     sequence_autoencoder.compile(optimizer='adam', \n",
    "#                                  loss='mse')\n",
    "#     return sequence_autoencoder, encoder, shape\n",
    "\n",
    "\n",
    "model, encoder = create_vae()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 620, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/300 [==>...........................] - ETA: 5:36 - loss: 0.3760"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 2:38 - loss: 2.8518"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 1:37 - loss: 1.9492"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 1:06 - loss: 1.4944"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/300 [===============>..............] - ETA: 46s - loss: 1.2094 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 31s - loss: 1.0230"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/300 [=====================>........] - ETA: 20s - loss: 0.8891"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 10s - loss: 0.7865"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r288/300 [===========================>..] - ETA: 2s - loss: 0.7043 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 68s 228ms/step - loss: 0.6778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/300 [==>...........................] - ETA: 48s - loss: 0.0434"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 37s - loss: 0.0488"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 31s - loss: 0.0502"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 23s - loss: 0.0480"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/300 [===============>..............] - ETA: 18s - loss: 0.0449"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 14s - loss: 0.0425"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/300 [=====================>........] - ETA: 10s - loss: 0.0405"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 5s - loss: 0.0392 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r288/300 [===========================>..] - ETA: 1s - loss: 0.0387"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 39s 129ms/step - loss: 0.0386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r 32/300 [==>...........................] - ETA: 27s - loss: 0.0356"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 64/300 [=====>........................] - ETA: 22s - loss: 0.0319"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 96/300 [========>.....................] - ETA: 20s - loss: 0.0289"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/300 [===========>..................] - ETA: 17s - loss: 0.0265"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r160/300 [===============>..............] - ETA: 15s - loss: 0.0250"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r192/300 [==================>...........] - ETA: 13s - loss: 0.0241"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r224/300 [=====================>........] - ETA: 9s - loss: 0.0235 "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def train():\n",
    "    \n",
    "    print(train_matrix.shape)\n",
    "    model.fit([train_matrix,train_matrix], epochs=15, verbose=1)\n",
    "    model.save_weights(\"Models/Weights/AE_CONV_LSTM_Diff_len_dist_MATRIX_LEN.hdf5\")\n",
    "\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 10) (300, 10) (300, 10)\n(300, 3)\n[0.6983651  0.23717883 0.04107158]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n[0.74839777 0.22248009 0.01759055]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n[0.6939893  0.23281148 0.04287714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n[0.6719166  0.18468654 0.10815211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 3)\n[0.6719133  0.18468542 0.10815584]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def return_mask(num, labs):\n",
    "    arg = np.squeeze(np.argwhere(labs == num))\n",
    "    return arg\n",
    "\n",
    "masks = [return_mask(num, np.array(labels)) for num in range(0, 9)]\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "encodings = encoder.predict(train_matrix)\n",
    "\n",
    "#enc_mean, enc_var, z_enc = encodings[0], encodings[1], encodings[2]\n",
    "enc_mean, enc_var, z_enc, state_h, state_c = encodings[0], encodings[1], encodings[2], encodings[3], encodings[4]\n",
    "\n",
    "print(enc_mean.shape, enc_var.shape, z_enc.shape)\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "\n",
    "\n",
    "\n",
    "def plot_pca(title, i): \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    markers = ['o', 'o', 'o', 'o', '^', '^', '^', '^', '^', '^']\n",
    "    for index, mask in enumerate(masks):\n",
    "        \n",
    "        ax.scatter(principalComponents[:, 0][mask], \n",
    "                   principalComponents[:, 1][mask],  \n",
    "                   principalComponents[:, 2][mask], marker=markers[index])\n",
    "    # for mask in unseen_mask:\n",
    "    #     ax.scatter(unseen_encoding[0][:,0][mask],\n",
    "    #                unseen_encoding[0][:,1][mask],\n",
    "    #                unseen_encoding[0][:,2][mask])\n",
    "    plt.legend(labels=np.arange(0, 9))\n",
    "    plt.title(str(title))\n",
    "    plt.show()\n",
    "    \n",
    "    for mask in masks:\n",
    "        plt.scatter(x=principalComponents[:, 0][mask], \n",
    "                    y=principalComponents[:, 1][mask],\n",
    "                    alpha=0.5)\n",
    "    # for mask in unseen_mask:\n",
    "    #     plt.scatter(unseen_encoding[0][:,0][mask],\n",
    "    #            unseen_encoding[0][:,1][mask])\n",
    "    #     \n",
    "        #break\n",
    "    \n",
    "    plt.legend(labels=np.arange(0, 9))\n",
    "    plt.title(str(title))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "enc_list = [enc_mean, enc_var, z_enc, state_h, state_c]\n",
    "titles = [\"MEAN\",\"LOG_VAR\",\"SAMPLED\", 'state_h', 'state_c']\n",
    "for i,enc in enumerate(enc_list):\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(enc) \n",
    "    pca = PCA(3)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    print(principalComponents.shape)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    plot_pca('Sequences'+titles[i], 0)\n",
    "    \n",
    "    # principalComponents = enc\n",
    "    # plot_pca('Sequences_Not_Pca'+titles[i], 0)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "628\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (636,4) into shape (620,4)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-b634c402c771>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m unseen_sequences_matrix, unseen_labs = prepare_training(\"Mix_sequences_var_length/run_unseen^\", \n\u001b[1;32m----> 2\u001b[1;33m                                            n_runs=300)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0munseen_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mreturn_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munseen_labs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0munseen_encoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munseen_sequences_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4094deedf4b3>\u001b[0m in \u001b[0;36mprepare_training\u001b[1;34m(path, n_runs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpadded_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mread_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Mix_sequences_var_length/run^\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_runs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_runs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4094deedf4b3>\u001b[0m in \u001b[0;36mread_sequences\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mrun_list_ordered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morder_runs_by_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_list_mix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mstands\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstadard_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_list_ordered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mpadded_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstands\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpadded_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4094deedf4b3>\u001b[0m in \u001b[0;36mconstruct_matrix\u001b[1;34m(sequence_list)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextend_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (636,4) into shape (620,4)"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "unseen_sequences_matrix, unseen_labs = prepare_training(\"Mix_sequences_var_length/run_unseen^\", \n",
    "                                           n_runs=300)\n",
    "unseen_mask = [return_mask(num, np.array(unseen_labs)) for num in range(0, 9)]\n",
    "\n",
    "unseen_encoding = encoder.predict(unseen_sequences_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 620, 4)\n"
     ]
    }
   ],
   "source": [
    "reconstruction = model.predict([train_matrix, train_matrix])\n",
    "print(reconstruction.shape)\n",
    "#RECONSTRUCTION\n",
    "def reconstruct_sequence(seq_index):\n",
    "    run = train_matrix[seq_index]\n",
    "    #mask_seq = np.squeeze(np.argwhere(np.mean(run, axis=1) != 0))\n",
    "    rec_run = reconstruction[seq_index]#[mask_seq]\n",
    "    #print(rec_run[:,0])\n",
    "    df = pd.DataFrame(rec_run[:-15], columns=[\"Sin\", \"Cosin\", \"Lat\", \"Lon\"])\n",
    "    df_original = pd.DataFrame(run[:-15], columns=[\"Sin\", \"Cosin\", \"Lat\", \"Lon\"])\n",
    "    plt.plot(df_original['Lon'], df_original['Lat'])\n",
    "    plt.plot(df['Lon'], df['Lat'])\n",
    "    plt.show()\n",
    "\n",
    "for i in range(len(train_matrix)):\n",
    "    reconstruct_sequence(i)\n",
    "    if i == 5:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights(\"Models/Weights/VAE_CONV_LSTM_Diff_len_dist_MATRIX_LEN.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "tsne_obj= tsne.fit_transform(enc_input)\n",
    "\n",
    "print(tsne_obj.shape)\n",
    "\n",
    "for mask in masks:\n",
    "    plt.scatter(x=tsne_obj[:, 0][mask], \n",
    "                y=tsne_obj[:, 1][mask],\n",
    "                alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RECONSTRUCTION\n",
    "def reconstruct_sequence(seq_index):\n",
    "    run = train_matrix[seq_index]\n",
    "    #mask_seq = np.squeeze(np.argwhere(np.mean(run, axis=1) != 0))\n",
    "    \n",
    "    reconstr_run = model.predict(np.reshape(run, (1, run.shape[0], run.shape[1])))\n",
    "    reconstr_run = np.reshape(reconstr_run, (run.shape[0], run.shape[1]))\n",
    "    reconstr_run = reconstr_run\n",
    "    df = pd.DataFrame(reconstr_run, columns=[\"Timestep\",\"Sin\", \"Cosin\", \"Lat\", \"Lon\"])\n",
    "    plt.plot(df['Lon'], df['Lat'])\n",
    "    plt.show()\n",
    "\n",
    "for i in range(len(train_matrix)):\n",
    "    reconstruct_sequence(i)\n",
    "    if i > 5:\n",
    "        break\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,) (200,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reconstruction = model.predict(train_matrix)\n",
    "reconstruction_unseen = model.predict(unseen_sequences_matrix)\n",
    "\n",
    "\n",
    "#RECONSTRUCTION ERROR\n",
    "def get_reconstructed_matrix(input_matrix, reconstrut):\n",
    "    return_matrix = np.zeros(shape=input_matrix.shape)\n",
    "    for i,run in enumerate(input_matrix):\n",
    "        mask_seq = np.squeeze(np.argwhere(np.mean(run, axis=1) != 0))\n",
    "        return_matrix[i][mask_seq] = reconstrut[i][mask_seq]    \n",
    "    return reconstrut\n",
    "\n",
    "\n",
    "train_error = abs(train_matrix-get_reconstructed_matrix(train_matrix,reconstruction))\n",
    "unseen_runs_error = abs(unseen_sequences_matrix-get_reconstructed_matrix(train_matrix,reconstruction_unseen))\n",
    "\n",
    "train_error_avg = np.mean(train_error, axis=2)\n",
    "unseen_error_avg = np.mean(unseen_runs_error, axis=2)\n",
    "train_error_avg = np.mean(train_error_avg, axis=1)\n",
    "unseen_error_avg = np.mean(unseen_error_avg, axis=1)\n",
    "print(train_error_avg.shape, unseen_error_avg.shape)\n",
    "\n",
    "for mask in masks:\n",
    "    plt.scatter(np.linspace(1,200,200)[mask],train_error_avg[mask])\n",
    "plt.title('ERROR ON TRAIN')\n",
    "plt.show()\n",
    "\n",
    "for mask in unseen_mask:\n",
    "    plt.scatter(np.linspace(1,200,200)[mask],unseen_error_avg[mask])\n",
    "plt.title('ERROR ON Unseen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "x, y, z = unseen_encoding[:,0], unseen_encoding[:,1], unseen_encoding[:,2]\n",
    "\n",
    "for mask in unseen_mask:\n",
    "    ipv.scatter(x[mask], y[mask], z[mask], size=0.3, marker=\"sphere\")\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.69657601e-04 2.90231335e-03 2.66825905e-01 5.29824561e-01\n  8.35837121e-01]\n [1.69657601e-04 2.90231335e-03 3.53738663e-01 5.49122807e-01\n  7.10645313e-01]\n [9.93304461e-03 5.59014899e-02 3.40350877e-01 7.50188854e-01\n  9.98851458e-01]\n ...\n [0.00000000e+00 6.14035088e-02 3.62061103e-01 4.36881822e-01\n  1.00000000e+00]\n [4.80214197e-03 2.02577052e-01 6.96491228e-01 7.76227370e-01\n  9.99448401e-01]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available(), torch.backends.cudnn.enabled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3990, 0.5784, 0.8855],\n        [0.1293, 0.7703, 0.6091],\n        [0.2355, 0.0893, 0.3447],\n        [0.3635, 0.8326, 0.8823],\n        [0.9676, 0.3495, 0.6277]])"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
