{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629\n(200, 640, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "n_features = 4 \n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_len_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\") \n",
    "labels = np.array(labels)\n",
    "max_len = 0\n",
    "\n",
    "\n",
    "def prepare_training(path, n_runs):\n",
    "    \n",
    "    def get_max_len(sequence_list):\n",
    "        m_len = 0\n",
    "        for seq in sequence_list:\n",
    "            if len(seq) > m_len:\n",
    "                m_len = len(seq)\n",
    "        max_len = m_len\n",
    "        print(max_len)\n",
    "        return m_len\n",
    "    \n",
    "    \n",
    "    def construct_matrix(sequence_list):\n",
    "        max_len = get_max_len(sequence_list)\n",
    "        max_len = 640\n",
    "        train_matrix = np.zeros(shape=(n_runs, max_len, n_features))\n",
    "        for index,run in enumerate(sequence_list):\n",
    "            train_matrix[index, :len(run)] = run\n",
    "        print(train_matrix.shape)\n",
    "        return train_matrix\n",
    "        \n",
    "        \n",
    "    def stadard_sequences(sequences):\n",
    "        for i, seq in enumerate(sequences):\n",
    "            sequences[i] = MinMaxScaler(feature_range=[0, 1]).fit_transform(seq)\n",
    "        return sequences       \n",
    "    \n",
    "    def read_sequences():\n",
    "        run_list_mix = []\n",
    "        for index in range(n_runs):\n",
    "            run_csv = pd.read_csv(path+str(index))\n",
    "            run_csv = run_csv.drop(columns=['Unnamed: 0'])\n",
    "            run_list_mix.append(run_csv)\n",
    "        stand_sequences = stadard_sequences(run_list_mix)\n",
    "        padded_matrix = construct_matrix(stand_sequences)\n",
    "        return padded_matrix\n",
    "    \n",
    "    \n",
    "    \n",
    "    return read_sequences()\n",
    "    \n",
    "\n",
    "train_matrix = prepare_training(\"Mix_sequences_var_length/run^\", n_runs=200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         (None, 640, 4)            0         \n_________________________________________________________________\nconv1d_11 (Conv1D)           (None, 320, 50)           450       \n_________________________________________________________________\nconv1d_12 (Conv1D)           (None, 160, 50)           5050      \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 30)                9720      \n_________________________________________________________________\ndense_16 (Dense)             (None, 10)                310       \n=================================================================\nTotal params: 15,530\nTrainable params: 15,530\nNon-trainable params: 0\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         (None, 640, 4)            0         \n_________________________________________________________________\nconv1d_11 (Conv1D)           (None, 320, 50)           450       \n_________________________________________________________________\nconv1d_12 (Conv1D)           (None, 160, 50)           5050      \n_________________________________________________________________\nlstm_6 (LSTM)                (None, 30)                9720      \n_________________________________________________________________\ndense_16 (Dense)             (None, 10)                310       \n_________________________________________________________________\nmodel_17 (Model)             (None, 640, 4)            98304     \n=================================================================\nTotal params: 113,834\nTrainable params: 113,834\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.layers import Input, LSTM, RepeatVector, Conv2DTranspose\n",
    "from keras.losses import mse\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "filters = 50\n",
    "intermediate_dimension = 30 \n",
    "latent_dim = 10\n",
    "\n",
    "def Conv1DTranspose(input_tensor, filters, kernel_size, strides=2, padding='same'):\n",
    "        x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "        x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), \n",
    "                            activation='relu',strides=(strides, 1), padding='valid')(x)\n",
    "        x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "def repeat(x):\n",
    "    steps_matrix = K.ones_like(x[0][:, :, :1])\n",
    "    \n",
    "    latent_matrix = K.expand_dims(x[1], axis=1)\n",
    "    return K.batch_dot(steps_matrix, latent_matrix)\n",
    "\n",
    "\n",
    "def create_vae():\n",
    "    print(max_len)\n",
    "    inputs = Input(shape=(624, n_features))\n",
    "    x = inputs\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = Conv1D(filters=filters,\n",
    "                   kernel_size=2,\n",
    "                   strides=2,\n",
    "                   padding='valid')(x)\n",
    "    \n",
    "    shape = K.int_shape(x)\n",
    "    x = LSTM(intermediate_dimension)(x)\n",
    "    embeddings = Dense(latent_dim)(x)\n",
    "    \n",
    "    z_mean = Dense(latent_dim, name='z_mean',)(embeddings)\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(embeddings)\n",
    "    z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "    \n",
    "    encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    latent_inputs = Input(shape=(latent_dim,), name='latent_inputs')\n",
    "    #x = Lambda(repeat)([before_flattening, z])\n",
    "    x = Dense(shape[1]*shape[2])(latent_inputs)\n",
    "    x = Reshape((shape[1],shape[2]))(x)\n",
    "    \n",
    "    \n",
    "    print(K.int_shape(x))\n",
    "    for i in range(2):\n",
    "        x = Conv1DTranspose(input_tensor=x,\n",
    "                            filters=filters,\n",
    "                            kernel_size=2,\n",
    "                            last=False,\n",
    "                            padding='valid')\n",
    "    \n",
    "    \n",
    "    output = Dense(n_features)(x)\n",
    "    \n",
    "    encoder.summary()\n",
    "    decoder = Model(latent_inputs, output)\n",
    "    decoder.summary()\n",
    "    outputs = decoder(encoder.outputs[2])\n",
    "    reconstruction_loss = K.categorical_crossentropy(K.flatten(inputs), K.flatten(outputs))\n",
    "    #reconstruction_loss *= sequence_length*4\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), \n",
    "                             axis=-1)\n",
    "    loss = K.mean(reconstruction_loss+kl_loss)\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "    vae.add_loss(loss)\n",
    "    #vae.summary()\n",
    "    vae.compile(optimizer='rmsprop')\n",
    "    return vae, encoder\n",
    "\n",
    "\n",
    "def create_ae():\n",
    "    inputs = Input(shape=(640, n_features))\n",
    "    x = inputs\n",
    "    for i in range(2):\n",
    "        x = Conv1D(filters=filters, kernel_size=2, strides=2,\n",
    "                   activation='relu',\n",
    "                   padding='valid')(x)\n",
    "    shape = K.int_shape(x)   \n",
    "    x = LSTM(intermediate_dimension)(x)\n",
    "    #x = Flatten()(x)\n",
    "    encoded = Dense(latent_dim)(x)\n",
    "    #x = Lambda(repeat)([before_flattening, encoded])\n",
    "    \n",
    "    latent_inputs = Input(shape=(latent_dim,), name='latent_inputs')\n",
    "    x = Dense(shape[1]*shape[2])(latent_inputs)\n",
    "    x = Reshape((shape[1],shape[2]))(x)\n",
    "    \n",
    "    for i in range(2):\n",
    "        x = Conv1DTranspose(input_tensor=x, filters=filters,\n",
    "                            kernel_size=2, padding='valid')\n",
    "\n",
    "       \n",
    "    #decoded = LSTM(n_features, return_sequences=True)(x)\n",
    "    \n",
    "    output = Dense(n_features, activation='softmax')(x)\n",
    "    \n",
    "    encoder = Model(inputs, encoded)\n",
    "    encoder.summary()\n",
    "    decoder = Model(latent_inputs, output)\n",
    "    \n",
    "    output = decoder(encoder.output)\n",
    "    sequence_autoencoder = Model(inputs, output)\n",
    "    sequence_autoencoder.summary()\n",
    "    sequence_autoencoder.compile(optimizer='rmsprop', \n",
    "                                 loss='categorical_crossentropy')\n",
    "    return sequence_autoencoder, encoder\n",
    "\n",
    "\n",
    "model, encoder = create_ae()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "def train():\n",
    "    \n",
    "    print(train_matrix.shape)\n",
    "    model.fit(train_matrix,train_matrix, epochs=100, verbose=1)\n",
    "    model.save_weights(\"Models/Weights/AE_CONV_LSTM_Diff_len_dist_MATRIX_LEN.hdf5\")\n",
    "\n",
    "\n",
    "train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luca\\Anaconda3\\envs\\Lstm_vae_boat_data\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights(\"Models/Weights/VAE_CONV_LSTM_Diff_len_dist_MATRIX_LEN.hdf5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 10) (200, 10) (200, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n[0.54929274 0.37255278 0.04746724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n[0.54929274 0.37255278 0.04746724]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 3)\n[0.54929274 0.37255278 0.04746724]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "encodings = encoder.predict(train_matrix)\n",
    "\n",
    "#enc_mean, enc_var, z_enc = encodings[0], encodings[1], encodings[2]\n",
    "enc_mean, enc_var, z_enc = encodings, encodings, encodings\n",
    "\n",
    "print(enc_mean.shape, enc_var.shape, z_enc.shape)\n",
    "\n",
    "\n",
    "def return_mask(num, labs):\n",
    "    arg = np.squeeze(np.argwhere(labs == num))\n",
    "    \n",
    "    \n",
    "    \n",
    "    return arg\n",
    "\n",
    "\n",
    "masks = [return_mask(num, np.array(labels))[:, 0] for num in range(0, 9)]\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D  \n",
    "\n",
    "\n",
    "\n",
    "def plot_pca(title, i): \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    markers = ['o', 'o', 'o', 'o', '^', '^', '^', '^', '^', '^']\n",
    "    for index, mask in enumerate(masks):\n",
    "        \n",
    "        ax.scatter(principalComponents[:, 0][mask], \n",
    "                   principalComponents[:, 1][mask],  \n",
    "                   principalComponents[:, 2][mask], marker=markers[index])\n",
    "    # for mask in unseen_mask:\n",
    "    #     ax.scatter(unseen_encoding[0][:,0][mask],\n",
    "    #                unseen_encoding[0][:,1][mask],\n",
    "    #                unseen_encoding[0][:,2][mask])\n",
    "    plt.legend(labels=np.arange(0, 9))\n",
    "    plt.title(str(title))\n",
    "    plt.show()\n",
    "    \n",
    "    for mask in masks:\n",
    "        plt.scatter(x=principalComponents[:, 0][mask], \n",
    "                    y=principalComponents[:, 1][mask],\n",
    "                    alpha=0.5)\n",
    "    # for mask in unseen_mask:\n",
    "    #     plt.scatter(unseen_encoding[0][:,0][mask],\n",
    "    #            unseen_encoding[0][:,1][mask])\n",
    "    #     \n",
    "        #break\n",
    "    \n",
    "    plt.legend(labels=np.arange(0, 9))\n",
    "    plt.title(str(title))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "enc_list = [enc_mean, enc_var, z_enc]\n",
    "titles = [\"MEAN\",\"LOG_VAR\",\"SAMPLED\"]\n",
    "for i,enc in enumerate(enc_list):\n",
    "    scaler = StandardScaler()\n",
    "    enc_input = scaler.fit_transform(enc) \n",
    "    pca = PCA(3)\n",
    "    principalComponents = pca.fit_transform(enc_input)\n",
    "    print(principalComponents.shape)\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    plot_pca('Sequences'+titles[i], 0)\n",
    "    \n",
    "    # principalComponents = enc\n",
    "    # plot_pca('Sequences_Not_Pca'+titles[i], 0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "\n",
    "tsne_obj= tsne.fit_transform(enc_input)\n",
    "\n",
    "print(tsne_obj.shape)\n",
    "\n",
    "for mask in masks:\n",
    "    plt.scatter(x=tsne_obj[:, 0][mask], \n",
    "                y=tsne_obj[:, 1][mask],\n",
    "                alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605\n(200, 640, 4)\n(200, 640, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 (10,)\n"
     ]
    }
   ],
   "source": [
    "unseen_labs = pd.read_csv(\"Data/Boat_nominal_data/Boat_unseen_labels_mix.csv\")\n",
    "unseen_labs = unseen_labs.drop(columns=\"Unnamed: 0\") \n",
    "unseen_labs = np.array(unseen_labs)\n",
    "unseen_mask = [return_mask(num, np.array(unseen_labs))[:, 0] for num in range(0, 9)]\n",
    "\n",
    "unseen_sequences_matrix = prepare_training(\"Mix_sequences_var_length/run_unseen^\", \n",
    "                                           n_runs=200)\n",
    "\n",
    "print(unseen_sequences_matrix.shape)\n",
    "unseen_encoding = encoder.predict(unseen_sequences_matrix)\n",
    "print(len(unseen_encoding), unseen_encoding[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RECONSTRUCTION\n",
    "def reconstruct_sequence(seq_index):\n",
    "    run = train_matrix[seq_index]\n",
    "    mask_seq = np.squeeze(np.argwhere(np.mean(run, axis=1) != 0))\n",
    "    \n",
    "    reconstr_run = model.predict(np.reshape(run, (1, run.shape[0], run.shape[1])))\n",
    "    reconstr_run = np.reshape(reconstr_run, (run.shape[0], run.shape[1]))\n",
    "    reconstr_run = reconstr_run[mask_seq]\n",
    "    df = pd.DataFrame(reconstr_run, columns=[\"Sin\", \"Cosin\", \"Lat\", \"Lon\"])\n",
    "    plt.plot(df['Lon'], df['Lat'])\n",
    "    plt.show()\n",
    "\n",
    "for i in range(len(train_matrix)):\n",
    "    reconstruct_sequence(i)\n",
    "    if i > 5:\n",
    "        break\n",
    "    \n",
    "reconstruction = model.predict(train_matrix)\n",
    "reconstruction_unseen = model.predict(unseen_sequences_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,) (200,)\n"
     ]
    }
   ],
   "source": [
    "#RECONSTRUCTION ERROR\n",
    "def get_reconstructed_matrix(input_matrix, reconstrut):\n",
    "    return_matrix = np.zeros(shape=input_matrix.shape)\n",
    "    for i,run in enumerate(input_matrix):\n",
    "        mask_seq = np.squeeze(np.argwhere(np.mean(run, axis=1) != 0))\n",
    "        return_matrix[i][mask_seq] = reconstrut[i][mask_seq]    \n",
    "    return reconstrut\n",
    "\n",
    "\n",
    "train_error = abs(train_matrix-get_reconstructed_matrix(train_matrix,reconstruction))\n",
    "unseen_runs_error = abs(unseen_sequences_matrix-get_reconstructed_matrix(train_matrix,reconstruction_unseen))\n",
    "\n",
    "train_error_avg = np.mean(train_error, axis=2)\n",
    "unseen_error_avg = np.mean(unseen_runs_error, axis=2)\n",
    "train_error_avg = np.mean(train_error_avg, axis=1)\n",
    "unseen_error_avg = np.mean(unseen_error_avg, axis=1)\n",
    "print(train_error_avg.shape, unseen_error_avg.shape)\n",
    "\n",
    "for mask in masks:\n",
    "    plt.scatter(np.linspace(1,200,200)[mask],train_error_avg[mask])\n",
    "plt.title('ERROR ON TRAIN')\n",
    "plt.show()\n",
    "\n",
    "for mask in unseen_mask:\n",
    "    plt.scatter(np.linspace(1,200,200)[mask],unseen_error_avg[mask])\n",
    "plt.title('ERROR ON Unseen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 0.0, 2.0), quaternion=(0.0, 0.0, 0.0, …"
      ]
     },
     "execution_count": 0,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyvolume as ipv\n",
    "import numpy as np\n",
    "x, y, z = unseen_encoding[:,0], unseen_encoding[:,1], unseen_encoding[:,2]\n",
    "\n",
    "for mask in unseen_mask:\n",
    "    ipv.scatter(x[mask], y[mask], z[mask], size=0.3, marker=\"sphere\")\n",
    "ipv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
