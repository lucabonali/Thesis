{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307200, 4)\n(300, 1024, 4)\n(30, 1024, 4)\n(300, 1024, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape\n",
    "from keras.layers import Conv1D,UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "n_features = 4\n",
    "sequence_length = 1024\n",
    "boat_csv = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequences_mix.csv\")\n",
    "boat_csv = boat_csv.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = StandardScaler()\n",
    "normal_data = scaler.fit_transform(boat_csv)\n",
    "print(normal_data.shape)\n",
    "\n",
    "boat_val = pd.read_csv(\"Data/Boat_nominal_data/Boat_sequence_mix_val.csv\")\n",
    "boat_val = boat_val.drop(columns=[\"Unnamed: 0\", \"M0C\", \"M1C\", \n",
    "                                  \"Acceleration\",\"Speed\"])\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "val_nom_data = scaler.fit_transform(boat_val)\n",
    "\n",
    "def prepare_sequences(data, batch_size):\n",
    "    samples = []\n",
    "    for i in range(0,data.shape[0], batch_size):\n",
    "        sample = data[i:i+batch_size]\t\n",
    "        samples.append(sample)\n",
    "    sequences = np.array(samples)\n",
    "    trainX = np.reshape(sequences, (len(sequences), batch_size, n_features))\n",
    "    return trainX\n",
    "\n",
    "\n",
    "def prepare_data():    \n",
    "    trainX_nominal = prepare_sequences(normal_data,sequence_length) \n",
    "    print(trainX_nominal.shape)\n",
    "    \n",
    "    valX_nominal = prepare_sequences(val_nom_data,sequence_length)\n",
    "    print(valX_nominal.shape)\n",
    "\n",
    "    return trainX_nominal, valX_nominal\n",
    "\n",
    "trainX_nominal, valX_nominal = prepare_data()\n",
    "n_sequences = len(trainX_nominal)\n",
    "trainX_nominal = np.reshape(trainX_nominal, [n_sequences, sequence_length, n_features , 1])\n",
    "print(trainX_nominal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024, 4, 1)\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nencoder_input (InputLayer)      (None, 1024, 4, 1)   0                                            \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 512, 2, 32)   160         encoder_input[0][0]              \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 256, 1, 64)   8256        conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nflatten_4 (Flatten)             (None, 16384)        0           conv2d_8[0][0]                   \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 16)           262160      flatten_4[0][0]                  \n__________________________________________________________________________________________________\nz_mean (Dense)                  (None, 20)           340         dense_7[0][0]                    \n__________________________________________________________________________________________________\nz_log_var (Dense)               (None, 20)           340         dense_7[0][0]                    \n__________________________________________________________________________________________________\nz (Lambda)                      (None, 20)           0           z_mean[0][0]                     \n                                                                 z_log_var[0][0]                  \n==================================================================================================\nTotal params: 271,256\nTrainable params: 271,256\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nz_sampling (InputLayer)      (None, 20)                0         \n_________________________________________________________________\ndense_8 (Dense)              (None, 16384)             344064    \n_________________________________________________________________\nreshape_4 (Reshape)          (None, 256, 1, 64)        0         \n_________________________________________________________________\nconv2d_transpose_10 (Conv2DT (None, 512, 2, 64)        16448     \n_________________________________________________________________\nconv2d_transpose_11 (Conv2DT (None, 1024, 4, 64)       16448     \n_________________________________________________________________\nconv2d_transpose_12 (Conv2DT (None, 1024, 4, 1)        257       \n=================================================================\nTotal params: 377,217\nTrainable params: 377,217\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nencoder_input (InputLayer)   (None, 1024, 4, 1)        0         \n_________________________________________________________________\nencoder (Model)              [(None, 20), (None, 20),  271256    \n_________________________________________________________________\ndecoder (Model)              (None, 1024, 4, 1)        377217    \n=================================================================\nTotal params: 648,473\nTrainable params: 648,473\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "\n",
    "# network parameters\n",
    "from keras.losses import mse\n",
    "\n",
    "input_shape = (sequence_length,n_features,1)\n",
    "batch_size = 128\n",
    "kernel_size = 2\n",
    "filters = 16\n",
    "latent_dim = 20\n",
    "epochs = 30\n",
    "\n",
    "# VAE model = encoder + decoder\n",
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "print(K.int_shape(x))\n",
    "for i in range(2):\n",
    "    filters *= 2\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=2,\n",
    "               padding='same',\n",
    "               activation='relu')(x)\n",
    "\n",
    "# shape info needed to build decoder model\n",
    "shape = K.int_shape(x)\n",
    "\n",
    "# generate latent vector Q(z|X)\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()\n",
    "\n",
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2]*shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "for i in range(2):\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        strides=2,\n",
    "                        padding='same',\n",
    "                        activation='relu')(x)\n",
    "\n",
    "\n",
    "outputs = Conv2DTranspose(filters=1,\n",
    "                          kernel_size=kernel_size,\n",
    "                          padding='same')(x)\n",
    "\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[1])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "models = (encoder, decoder)\n",
    "# data = (x_test, y_test)\n",
    "\n",
    "# VAE loss = mse_loss or xent_loss + kl_loss\n",
    "reconstruction_loss = mse(K.flatten(inputs), K.flatten(outputs))\n",
    "\n",
    "\n",
    "reconstruction_loss *= 1024*4\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='rmsprop')\n",
    "vae.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 3s - loss: 4091.1777"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 4101.8843"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 4s 13ms/step - loss: 4099.1893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 4030.3477"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 3884.7424"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 3746.5890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 2394.8438"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 2403.3229"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 2341.6396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 1298.5941"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 1150.0007"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 1112.6641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 822.1349"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 802.0539"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 792.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 722.2990"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 712.8308"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 706.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 582.5961"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 553.7083"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 541.5791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 453.6088"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 446.4185"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 459.6832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 533.0196"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 674.7947"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 8ms/step - loss: 631.0564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r128/300 [===========>..................] - ETA: 1s - loss: 432.5953"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r256/300 [========================>.....] - ETA: 0s - loss: 397.0203"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r300/300 [==============================] - 2s 7ms/step - loss: 402.8710\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vae.fit(trainX_nominal,\n",
    "        epochs=10,\n",
    "        batch_size=batch_size)\n",
    "vae.save_weights('Conv2d_vae.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 20)\n(300, 20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def return_mask(num, labels):\n",
    "    return np.squeeze(np.argwhere(labels == num))\n",
    "\n",
    "labels = pd.read_csv(\"Data/Boat_nominal_data/Boat_mix_labels.csv\")\n",
    "labels = labels.drop(columns=\"Unnamed: 0\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "masks = [return_mask(num,labels)[:,0] for num in range(0,9)]\n",
    "\n",
    "\n",
    "encodings = encoder.predict(trainX_nominal)\n",
    "\n",
    "def check_z_sampling(encoded_values):\n",
    "    m = encoded_values[0]\n",
    "    var = np.exp(0.5*encoded_values[1])\n",
    "    eps = np.random.normal(0,1,latent_dim)\n",
    "    \n",
    "    sampled = []\n",
    "    index = 0\n",
    "    var_zero = np.zeros(10)\n",
    "    for means in m:\n",
    "        sample = means+var[index]*eps\n",
    "        #sample = means+var_zero*eps \n",
    "        sampled.append(sample)\n",
    "        index += 1\n",
    "    \n",
    "    sampled = np.array(sampled)\n",
    "    return sampled\n",
    "\n",
    "# def plot_pca(title, type): \n",
    "#     x_val = []\n",
    "#     y_val= []\n",
    "#     for i in range(principalComponents.shape[0]):\n",
    "#         x_val.append(principalComponents[i][0])\n",
    "#         y_val.append(principalComponents[i][1])\n",
    "#     x_val = np.array(x_val)\n",
    "#     y_val = np.array(y_val)\n",
    "#     \n",
    "#     for mask in masks:\n",
    "#         plt.scatter(x=x_val[mask], y=y_val[mask], alpha=0.5)\n",
    "# \n",
    "#     plt.legend(labels=np.arange(0,9))\n",
    "#     plt.title(str(title)+\"\"+type)\n",
    "#     plt.show()\n",
    "#     \n",
    "titles=['z_mean','z_log_var','z']\n",
    "for i in range(3):\n",
    "    latent_values = check_z_sampling(encodings)\n",
    "    print(encodings[i].shape)\n",
    "    for mask in masks:\n",
    "        plt.scatter(x=encodings[i][:, 0][mask], \n",
    "                    y=encodings[i][:, 1][mask], alpha=0.5)\n",
    "    plt.title(titles[i])\n",
    "    plt.legend(labels=np.arange(0,9))\n",
    "    plt.show()\n",
    "    # \n",
    "    # scaler = StandardScaler()\n",
    "    # enc_input = scaler.fit_transform(encodings[i]) \n",
    "    # pca = PCA(2)\n",
    "    # principalComponents = pca.fit_transform(enc_input)\n",
    "    # plt.scatter(enc_input[0][:, 0], enc_input[0][:, 1])\n",
    "    # plt.show()\n",
    "    # principalComponents\n",
    "    # #print(pca.explained_variance_ratio_)\n",
    "    # plot_pca(' ', titles[i])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619, 1024, 4, 1)\n(42, 1024, 4, 1)\n(42, 1024, 4, 1)\n(51, 1024, 4, 1)\n(49, 1024, 4, 1)\n(59, 1024, 4, 1)\n(42, 1024, 4, 1)\n(48, 1024, 4, 1)\n(48, 1024, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "for mask in masks:\n",
    "    run_for_class = trainX_nominal[mask]\n",
    "    print(run_for_class.shape)\n",
    "    runs.append(run_for_class)\n",
    "\n",
    "for j in range(9):    \n",
    "    for i in runs[j]:\n",
    "        run = np.reshape(i, (1, 1024,4, 1))\n",
    "        rec = vae.predict(run)\n",
    "        rec = np.reshape(rec, (len(trainX_nominal[0]), n_features))\n",
    "        reconstruction_df = pd.DataFrame(rec, columns=boat_csv.columns)\n",
    "        \n",
    "        plt.plot(reconstruction_df[\"Lon\"], reconstruction_df[\"Lat\"])\n",
    "        #plt.savefig(\"Imgs/Latent_reconstruction/\"+str(title)+\".png\")\n",
    "        plt.show()\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
